{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>company</th>\n",
       "      <th>gas</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2497.129</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2363.265</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2258.505</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2243.969</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2344.105</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361478</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>181.907</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361479</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>166.607</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361480</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>173.503</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361481</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>191.135</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361482</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>219.185</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90883 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  hour  company       gas  year  month  day  weekday\n",
       "0      2013-01-01     1        0  2497.129  2013      1    1        1\n",
       "1      2013-01-01     2        0  2363.265  2013      1    1        1\n",
       "2      2013-01-01     3        0  2258.505  2013      1    1        1\n",
       "3      2013-01-01     4        0  2243.969  2013      1    1        1\n",
       "4      2013-01-01     5        0  2344.105  2013      1    1        1\n",
       "...           ...   ...      ...       ...   ...    ...  ...      ...\n",
       "361478 2018-03-31    15        6   181.907  2018      3   31        5\n",
       "361479 2018-03-31    16        6   166.607  2018      3   31        5\n",
       "361480 2018-03-31    17        6   173.503  2018      3   31        5\n",
       "361481 2018-03-31    18        6   191.135  2018      3   31        5\n",
       "361482 2018-03-31    19        6   219.185  2018      3   31        5\n",
       "\n",
       "[90883 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.read_csv('./Data/한국가스공사_시간별 공급량_20181231.csv', encoding='cp949')\n",
    "total.columns = ['date', 'hour', 'company', 'gas']\n",
    "\n",
    "\n",
    "companys = total['company'].unique()\n",
    "company_map = dict()\n",
    "for i, company in enumerate(companys):\n",
    "    company_map[company] = i\n",
    "total['company'] = total['company'].map(company_map)\n",
    "total['date'] = pd.to_datetime(total['date'])\n",
    "total['year'] = total['date'].dt.year\n",
    "total['month'] = total['date'].dt.month\n",
    "total['day'] = total['date'].dt.day\n",
    "total['weekday'] = total['date'].dt.weekday\n",
    "\n",
    "\n",
    "total = total[total['month'].isin([1,2,3])]\n",
    "total.head(-5)\n",
    "#total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'G': 5, 'H': 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8784, 7)\n",
      "(8756, 7)\n",
      "(8759, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temps = []\n",
    "for year in range(2013, 2019):\n",
    "    temp = pd.read_csv(f'./Data/temperature_{year}.csv', encoding='cp949')\n",
    "    #temp.columns = header\n",
    "    temp = temp[['일시', '기온(°C)']]\n",
    "    temp.columns = ['datetime', 'temperature']\n",
    "    temp['datetime'] = pd.to_datetime(temp['datetime'])\n",
    "    temp['year'] = temp['datetime'].dt.year\n",
    "    temp['month'] = temp['datetime'].dt.month\n",
    "    temp['day'] = temp['datetime'].dt.day\n",
    "    temp['weekday'] = temp['datetime'].dt.weekday\n",
    "    temp['hour'] = temp['datetime'].dt.hour + 1\n",
    "    print(temp.shape)\n",
    "    temps.append(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime  temperature  year  month  day  weekday  hour\n",
      "0 2014-12-31 23:00:00         -6.2  2014     12   31        2    24\n",
      "1 2015-01-01 01:00:00         -7.4  2015      1    1        3     2\n",
      "2 2015-01-01 02:00:00         -8.0  2015      1    1        3     3\n",
      "3 2015-01-01 03:00:00         -8.4  2015      1    1        3     4\n",
      "4 2015-01-01 04:00:00         -8.8  2015      1    1        3     5\n",
      "             datetime  temperature  year  month  day  weekday  hour\n",
      "0 2015-01-01 00:00:00         -6.2  2015      1    1        3     1\n",
      "1 2015-01-01 01:00:00         -7.4  2015      1    1        3     2\n",
      "2 2015-01-01 02:00:00         -8.0  2015      1    1        3     3\n",
      "3 2015-01-01 03:00:00         -8.4  2015      1    1        3     4\n",
      "4 2015-01-01 04:00:00         -8.8  2015      1    1        3     5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/woojaebyun/miniforge3/envs/mlp/lib/python3.8/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# interpolation for 2015\n",
    "\n",
    "print(temps[2].head())\n",
    "temps[2]['datetime'].iloc[0] = pd.to_datetime(\"2015-01-01 00:00:00\")\n",
    "temps[2]['year'].iloc[0] = 2015\n",
    "temps[2]['month'].iloc[0] = 1\n",
    "temps[2]['day'].iloc[0] = 1\n",
    "temps[2]['weekday'].iloc[0] = 3\n",
    "temps[2]['hour'].iloc[0] = 1\n",
    "\n",
    "print(temps[2].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6449 6831 6832 6833]\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6448 2017-09-26 16:00:00         30.4  2017      9   26        1    17\n",
      "6449 2017-09-26 18:00:00         27.9  2017      9   26        1    19\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6829 2017-10-12 14:00:00         13.7  2017     10   12        3    15\n",
      "6830 2017-10-12 18:00:00         12.8  2017     10   12        3    19\n",
      "6831 2017-10-12 19:00:00         11.5  2017     10   12        3    20\n",
      "6832 2017-10-12 20:00:00         10.6  2017     10   12        3    21\n",
      "6833 2017-10-12 21:00:00         10.2  2017     10   12        3    22\n",
      "6834 2017-10-12 22:00:00          9.7  2017     10   12        3    23\n",
      "29.15\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6448 2017-09-26 16:00:00        30.40  2017      9   26        1    17\n",
      "6449 2017-09-26 17:00:00        29.15  2017      9   26        1    18\n",
      "6450 2017-09-26 18:00:00        27.90  2017      9   26        1    19\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6829 2017-10-12 13:00:00         13.5  2017     10   12        3    14\n",
      "6830 2017-10-12 14:00:00         13.7  2017     10   12        3    15\n",
      "6831 2017-10-12 15:00:00         13.5  2017     10   12        3    16\n",
      "6832 2017-10-12 16:00:00         13.3  2017     10   12        3    17\n",
      "6833 2017-10-12 17:00:00         13.1  2017     10   12        3    18\n",
      "6834 2017-10-12 18:00:00         12.8  2017     10   12        3    19\n",
      "6835 2017-10-12 19:00:00         11.5  2017     10   12        3    20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/y3tvnwx10nqc9qqg0b1wb7wr0000gn/T/ipykernel_86419/2936941575.py:3: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  missing_indices = pd.isnull(temps[-2].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0]\n"
     ]
    }
   ],
   "source": [
    "# interpolation for 2017\n",
    "\n",
    "missing_indices = pd.isnull(temps[-2].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0]\n",
    "print(missing_indices)\n",
    "\n",
    "print(temps[-2].iloc[6448:6450])    \n",
    "print(temps[-2].iloc[6829:6835])\n",
    "\n",
    "calc_temp = temps[-2]['temperature'].iloc[6448:6450].mean()\n",
    "print(calc_temp)\n",
    "line = pd.DataFrame({\"datetime\": pd.to_datetime(\"2017-09-26 17:00:00\"), 'temperature': calc_temp, \"year\": 2017, 'month': 9, 'day':26, \\\n",
    "                  'weekday':1, 'hour': 18}, index=[6449] )\n",
    "\n",
    "\n",
    "lines = \\\n",
    "pd.DataFrame({\"datetime\": [pd.to_datetime(\"2017-10-12 15:00:00\"), pd.to_datetime(\"2017-10-12 16:00:00\"), pd.to_datetime(\"2017-10-12 17:00:00\")], \\\n",
    "              'temperature': [13.5, 13.3, 13.1], \\\n",
    "              \"year\": [2017, 2017, 2017], 'month': [10, 10, 10], \\\n",
    "              'day':[12,12,12], 'weekday':[3,3,3], 'hour': [16,17,18]}, \\\n",
    "              index=[6830, 6831, 6832] )\n",
    "\n",
    "\n",
    "\n",
    "temps[-2] = pd.concat([temps[-2].iloc[:6449], line, temps[-2].iloc[6449:6830], lines, temps[-2].iloc[6830:]]).reset_index(drop=True)\n",
    "\n",
    "print(temps[-2].iloc[6448:6451])    \n",
    "print(temps[-2].iloc[6829:6836])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7986]\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "7985 2018-11-29 17:00:00          5.8  2018     11   29        3    18\n",
      "7986 2018-11-29 19:00:00          5.2  2018     11   29        3    20\n",
      "5.5\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "7985 2018-11-29 17:00:00          5.8  2018     11   29        3    18\n",
      "7986 2018-11-29 18:00:00          5.5  2018     11   29        3    19\n",
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8784, 7)\n",
      "(8760, 7)\n",
      "(8760, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/y3tvnwx10nqc9qqg0b1wb7wr0000gn/T/ipykernel_86419/2492857734.py:3: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  print(pd.isnull(temps[-1].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0])\n"
     ]
    }
   ],
   "source": [
    "# interpolation for 2018\n",
    "\n",
    "print(pd.isnull(temps[-1].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0])\n",
    "print(temps[-1].iloc[7985:7987])\n",
    "\n",
    "calc_temp = temps[-1]['temperature'].iloc[7985:7987].mean()\n",
    "print(calc_temp)\n",
    "line = pd.DataFrame({\"datetime\": pd.to_datetime(\"2018-11-29 18:00:00\"), 'temperature': calc_temp, \"year\": 2018, 'month': 11, 'day':29, \\\n",
    "                  'weekday':3, 'hour': 19}, index=[7986] )\n",
    "temps[-1] = pd.concat([temps[-1].iloc[:7986], line, temps[-1].iloc[7986:]]).reset_index(drop=True)\n",
    "                  \n",
    "                  \n",
    "print(temps[-1].iloc[7985:7987])\n",
    "\n",
    "\n",
    "for i in range(len(temps)):\n",
    "    print(temps[i].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52584, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_combined = pd.concat(temps, axis = 0)\n",
    "temp_combined.reset_index(inplace=True, drop=True)\n",
    "temp_combined.shape # should be 52584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90888, 9)\n",
      "(90888, 8)\n",
      "         date  hour  company       gas  year  month  day  weekday  temperature\n",
      "0  2013-01-01     1        0  2497.129  2013      1    1        1         -8.3\n",
      "1  2013-01-01     2        0  2363.265  2013      1    1        1         -8.5\n",
      "2  2013-01-01     3        0  2258.505  2013      1    1        1         -8.4\n",
      "3  2013-01-01     4        0  2243.969  2013      1    1        1         -8.1\n",
      "4  2013-01-01     5        0  2344.105  2013      1    1        1         -8.2\n",
      "5  2013-01-01     6        0  2390.961  2013      1    1        1         -8.2\n",
      "6  2013-01-01     7        0  2378.457  2013      1    1        1         -8.6\n",
      "7  2013-01-01     8        0  2518.921  2013      1    1        1         -8.3\n",
      "8  2013-01-01     9        0  2706.481  2013      1    1        1         -7.9\n",
      "9  2013-01-01    10        0  2832.057  2013      1    1        1         -7.0\n",
      "10 2013-01-01    11        0  2895.185  2013      1    1        1         -5.5\n",
      "11 2013-01-01    12        0  2689.361  2013      1    1        1         -4.2\n",
      "12 2013-01-01    13        0  2425.537  2013      1    1        1         -4.2\n",
      "13 2013-01-01    14        0  2254.289  2013      1    1        1         -1.9\n",
      "14 2013-01-01    15        0  2153.361  2013      1    1        1         -0.6\n",
      "15 2013-01-01    16        0  2126.969  2013      1    1        1         -0.5\n",
      "16 2013-01-01    17        0  2210.481  2013      1    1        1         -0.6\n",
      "17 2013-01-01    18        0  2546.873  2013      1    1        1         -1.1\n",
      "18 2013-01-01    19        0  2886.097  2013      1    1        1         -1.7\n",
      "19 2013-01-01    20        0  2863.009  2013      1    1        1         -1.6\n",
      "         date  hour  company       gas  year  month  day  weekday\n",
      "0  2013-01-01     1        0  2497.129  2013      1    1        1\n",
      "1  2013-01-01     2        0  2363.265  2013      1    1        1\n",
      "2  2013-01-01     3        0  2258.505  2013      1    1        1\n",
      "3  2013-01-01     4        0  2243.969  2013      1    1        1\n",
      "4  2013-01-01     5        0  2344.105  2013      1    1        1\n",
      "5  2013-01-01     6        0  2390.961  2013      1    1        1\n",
      "6  2013-01-01     7        0  2378.457  2013      1    1        1\n",
      "7  2013-01-01     8        0  2518.921  2013      1    1        1\n",
      "8  2013-01-01     9        0  2706.481  2013      1    1        1\n",
      "9  2013-01-01    10        0  2832.057  2013      1    1        1\n",
      "10 2013-01-01    11        0  2895.185  2013      1    1        1\n",
      "11 2013-01-01    12        0  2689.361  2013      1    1        1\n",
      "12 2013-01-01    13        0  2425.537  2013      1    1        1\n",
      "13 2013-01-01    14        0  2254.289  2013      1    1        1\n",
      "14 2013-01-01    15        0  2153.361  2013      1    1        1\n",
      "15 2013-01-01    16        0  2126.969  2013      1    1        1\n",
      "16 2013-01-01    17        0  2210.481  2013      1    1        1\n",
      "17 2013-01-01    18        0  2546.873  2013      1    1        1\n",
      "18 2013-01-01    19        0  2886.097  2013      1    1        1\n",
      "19 2013-01-01    20        0  2863.009  2013      1    1        1\n"
     ]
    }
   ],
   "source": [
    "join_df = pd.merge(total, temp_combined, how='left', left_on=['year', 'month', 'day', 'weekday', 'hour'], right_on=['year', 'month', 'day', 'weekday', 'hour'])\n",
    "join_df.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(join_df.shape)\n",
    "print(total.shape)\n",
    "\n",
    "\n",
    "print(join_df.iloc[:20])\n",
    "print(total.iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2184, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>-2.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">31</th>\n",
       "      <th>20</th>\n",
       "      <td>12.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2184 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                temperature\n",
       "month day hour             \n",
       "1     1   1       -2.683333\n",
       "          2       -3.116667\n",
       "          3       -3.483333\n",
       "          4       -3.716667\n",
       "          5       -4.050000\n",
       "...                     ...\n",
       "3     31  20      12.883333\n",
       "          21      11.800000\n",
       "          22      11.083333\n",
       "          23      10.450000\n",
       "          24       9.950000\n",
       "\n",
       "[2184 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_temp = join_df[['temperature']].groupby([ join_df['month'], join_df['day'], join_df['hour'] ]).apply(lambda c: c.mean())\n",
    "print(daily_temp.shape)\n",
    "daily_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = ['temperature', 'company', 'month', 'day', 'weekday', 'hour', 'year']\n",
    "features = ['temperature', 'company', 'month', 'day', 'weekday', 'hour']\n",
    "\n",
    "\n",
    "train_x_lst = []\n",
    "train_y_lst   = []\n",
    "\n",
    "val_x_lst = []\n",
    "val_y_lst = []\n",
    "\n",
    "for year in range(2013, 2019):\n",
    "    train = join_df[join_df['year'] != year].reset_index(drop = True)\n",
    "    val   = join_df[join_df['year'] == year].reset_index(drop = True)\n",
    "    \n",
    "    train_x = train[features]\n",
    "    train_y = train['gas']\n",
    "    train_x = train_x.values\n",
    "    train_y = np.expand_dims(train_y.values, axis = 1)\n",
    "    \n",
    "    val_x = val[features]\n",
    "    val_y = val['gas']\n",
    "    val_x = val_x.values\n",
    "    val_y = np.expand_dims(val_y.values, axis = 1)\n",
    "    \n",
    "    train_x_lst.append(train_x)\n",
    "    train_y_lst.append(train_y)\n",
    "    \n",
    "    val_x_lst.append(val_x)\n",
    "    val_y_lst.append(val_y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.3 0.  1.  1.  2.  1. ]\n",
      " [2.6 0.  1.  1.  2.  2. ]\n",
      " [1.7 0.  1.  1.  2.  3. ]\n",
      " [1.4 0.  1.  1.  2.  4. ]\n",
      " [0.9 0.  1.  1.  2.  5. ]]\n",
      "[[1677.257]\n",
      " [1567.057]\n",
      " [1458.089]\n",
      " [1458.449]\n",
      " [1587.713]]\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[3.3 0.  1.  1.  2.  1. ]\n",
      " [2.6 0.  1.  1.  2.  2. ]\n",
      " [1.7 0.  1.  1.  2.  3. ]\n",
      " [1.4 0.  1.  1.  2.  4. ]\n",
      " [0.9 0.  1.  1.  2.  5. ]]\n",
      "[[1677.257]\n",
      " [1567.057]\n",
      " [1458.089]\n",
      " [1458.449]\n",
      " [1587.713]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[-6.2  0.   1.   1.   3.   1. ]\n",
      " [-7.4  0.   1.   1.   3.   2. ]\n",
      " [-8.   0.   1.   1.   3.   3. ]\n",
      " [-8.4  0.   1.   1.   3.   4. ]\n",
      " [-8.8  0.   1.   1.   3.   5. ]]\n",
      "[[2228.705]\n",
      " [2098.593]\n",
      " [1960.353]\n",
      " [1959.521]\n",
      " [2061.841]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[-1.9  0.   1.   1.   4.   1. ]\n",
      " [-2.1  0.   1.   1.   4.   2. ]\n",
      " [-2.2  0.   1.   1.   4.   3. ]\n",
      " [-2.5  0.   1.   1.   4.   4. ]\n",
      " [-2.9  0.   1.   1.   4.   5. ]]\n",
      "[[1677.553]\n",
      " [1570.025]\n",
      " [1468.241]\n",
      " [1446.145]\n",
      " [1555.353]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[ 0.2  0.   1.   1.   6.   1. ]\n",
      " [ 0.   0.   1.   1.   6.   2. ]\n",
      " [-0.3  0.   1.   1.   6.   3. ]\n",
      " [-0.7  0.   1.   1.   6.   4. ]\n",
      " [-1.1  0.   1.   1.   6.   5. ]]\n",
      "[[1637.137]\n",
      " [1528.425]\n",
      " [1425.081]\n",
      " [1422.889]\n",
      " [1519.809]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[-3.2  0.   1.   1.   0.   1. ]\n",
      " [-3.3  0.   1.   1.   0.   2. ]\n",
      " [-3.7  0.   1.   1.   0.   3. ]\n",
      " [-4.   0.   1.   1.   0.   4. ]\n",
      " [-4.2  0.   1.   1.   0.   5. ]]\n",
      "[[1765.008]\n",
      " [1679.186]\n",
      " [1610.885]\n",
      " [1604.123]\n",
      " [1711.506]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_x, train_y, val_x, val_y in zip(train_x_lst, train_y_lst, val_x_lst, val_y_lst):\n",
    "    print(train_x[:5])\n",
    "    print(train_y[:5])\n",
    "    print(val_x[:5])\n",
    "    print(val_y[:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model():    \n",
    "    input_data  = layers.Input(shape=(6,))\n",
    "    out         = layers.Dense(64, activation=\"relu\")(input_data)\n",
    "    out         = layers.BatchNormalization()(out)\n",
    "    out         = layers.Dense(32, activation=\"relu\")(out)\n",
    "    out         = layers.BatchNormalization()(out)\n",
    "    out         = layers.Dense(16, activation=\"relu\")(out)\n",
    "    out         = layers.BatchNormalization()(out)\n",
    "    output      = layers.Dense(1)(out)\n",
    "\n",
    "    model        = tf.keras.Model(inputs = input_data, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size = 0.2, random_state = 1311, shuffle=True)\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def n_mae(y_true, y_pred):\n",
    "    #y_true = y_scaler.inverse_transform(y_true)\n",
    "    #y_pred = y_scaler.inverse_transform(y_pred)\n",
    "    return K.mean((K.abs(y_true-y_pred))/y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:03:04.500648: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-31 13:03:04.503516: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/592 [..............................] - ETA: 3:39 - loss: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:03:04.744393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - ETA: 0s - loss: 0.9696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:03:11.900190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 8s 12ms/step - loss: 0.9696 - val_loss: 0.9459\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94595, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_001_Val_0.946.hdf5\n",
      "Epoch 2/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8674 - val_loss: 0.8420\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.94595 to 0.84199, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_002_Val_0.842.hdf5\n",
      "Epoch 3/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7900 - val_loss: 0.7590\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.84199 to 0.75896, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_003_Val_0.759.hdf5\n",
      "Epoch 4/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7383 - val_loss: 0.7160\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.75896 to 0.71604, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_004_Val_0.716.hdf5\n",
      "Epoch 5/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6989 - val_loss: 0.6889\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71604 to 0.68895, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_005_Val_0.689.hdf5\n",
      "Epoch 6/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6596 - val_loss: 0.6640\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68895 to 0.66397, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_006_Val_0.664.hdf5\n",
      "Epoch 7/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6128 - val_loss: 0.6274\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.66397 to 0.62739, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_007_Val_0.627.hdf5\n",
      "Epoch 8/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5672 - val_loss: 0.5709\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62739 to 0.57089, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_008_Val_0.571.hdf5\n",
      "Epoch 9/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5222 - val_loss: 0.5184\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.57089 to 0.51844, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_009_Val_0.518.hdf5\n",
      "Epoch 10/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4798 - val_loss: 0.4888\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.51844 to 0.48881, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_010_Val_0.489.hdf5\n",
      "Epoch 11/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4423 - val_loss: 0.4461\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.48881 to 0.44613, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_011_Val_0.446.hdf5\n",
      "Epoch 12/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4058 - val_loss: 0.4050\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44613 to 0.40502, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_012_Val_0.405.hdf5\n",
      "Epoch 13/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3765 - val_loss: 0.3692\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.40502 to 0.36917, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_013_Val_0.369.hdf5\n",
      "Epoch 14/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3455 - val_loss: 0.3300\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.36917 to 0.32996, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_014_Val_0.330.hdf5\n",
      "Epoch 15/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3214 - val_loss: 0.3101\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.32996 to 0.31010, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_015_Val_0.310.hdf5\n",
      "Epoch 16/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2981 - val_loss: 0.2957\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.31010 to 0.29574, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_016_Val_0.296.hdf5\n",
      "Epoch 17/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2759 - val_loss: 0.2652\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.29574 to 0.26520, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_017_Val_0.265.hdf5\n",
      "Epoch 18/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2551 - val_loss: 0.2686\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26520\n",
      "Epoch 19/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2376 - val_loss: 0.2494\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.26520 to 0.24942, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_019_Val_0.249.hdf5\n",
      "Epoch 20/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2213 - val_loss: 0.2214\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.24942 to 0.22140, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_020_Val_0.221.hdf5\n",
      "Epoch 21/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2094 - val_loss: 0.2056\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22140 to 0.20561, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_021_Val_0.206.hdf5\n",
      "Epoch 22/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1960 - val_loss: 0.2131\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20561\n",
      "Epoch 23/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1839 - val_loss: 0.1777\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.20561 to 0.17773, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_023_Val_0.178.hdf5\n",
      "Epoch 24/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1734 - val_loss: 0.1773\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.17773 to 0.17729, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_024_Val_0.177.hdf5\n",
      "Epoch 25/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1645 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.17729 to 0.16822, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_025_Val_0.168.hdf5\n",
      "Epoch 26/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1501 - val_loss: 0.1463\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16822 to 0.14632, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_026_Val_0.146.hdf5\n",
      "Epoch 27/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1471 - val_loss: 0.1431\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.14632 to 0.14315, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_027_Val_0.143.hdf5\n",
      "Epoch 28/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1380 - val_loss: 0.1591\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.14315\n",
      "Epoch 29/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1338 - val_loss: 0.1433\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14315\n",
      "Epoch 30/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1275 - val_loss: 0.1590\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14315\n",
      "Epoch 31/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1220 - val_loss: 0.1345\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.14315 to 0.13445, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_031_Val_0.134.hdf5\n",
      "Epoch 32/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1198 - val_loss: 0.1294\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.13445 to 0.12941, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_032_Val_0.129.hdf5\n",
      "Epoch 33/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1193 - val_loss: 0.1326\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.12941\n",
      "Epoch 34/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1166 - val_loss: 0.1249\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.12941 to 0.12490, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_034_Val_0.125.hdf5\n",
      "Epoch 35/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1121 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.12490 to 0.11890, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_035_Val_0.119.hdf5\n",
      "Epoch 36/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1114 - val_loss: 0.1204\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11890\n",
      "Epoch 37/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1090 - val_loss: 0.1181\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11890 to 0.11807, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_037_Val_0.118.hdf5\n",
      "Epoch 38/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1089 - val_loss: 0.1086\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.11807 to 0.10857, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_038_Val_0.109.hdf5\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1062 - val_loss: 0.1105\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10857\n",
      "Epoch 40/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1052 - val_loss: 0.1211\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10857\n",
      "Epoch 41/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1028 - val_loss: 0.1393\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10857\n",
      "Epoch 42/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1008 - val_loss: 0.1079\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10857 to 0.10786, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_042_Val_0.108.hdf5\n",
      "Epoch 43/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1031 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.10786 to 0.10608, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_043_Val_0.106.hdf5\n",
      "Epoch 44/50\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1011 - val_loss: 0.0944\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.10608 to 0.09438, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_044_Val_0.094.hdf5\n",
      "Epoch 45/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1007 - val_loss: 0.1089\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.09438\n",
      "Epoch 46/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0988 - val_loss: 0.0944\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.09438\n",
      "Epoch 47/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1037 - val_loss: 0.1030\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.09438\n",
      "Epoch 48/50\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0980 - val_loss: 0.0901\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.09438 to 0.09008, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_048_Val_0.090.hdf5\n",
      "Epoch 49/50\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0964 - val_loss: 0.1165\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.09008\n",
      "Epoch 50/50\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0962 - val_loss: 0.1125\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.09008\n",
      "Epoch 1/50\n",
      "  6/592 [..............................] - ETA: 6s - loss: 1.0000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:08:51.716130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:08:58.189314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.9701 - val_loss: 0.9364\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93636, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_001_Val_0.936.hdf5\n",
      "Epoch 2/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8690 - val_loss: 0.8379\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93636 to 0.83789, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_002_Val_0.838.hdf5\n",
      "Epoch 3/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.8025 - val_loss: 0.7709\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.83789 to 0.77087, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_003_Val_0.771.hdf5\n",
      "Epoch 4/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7534 - val_loss: 0.7229\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.77087 to 0.72285, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_004_Val_0.723.hdf5\n",
      "Epoch 5/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7086 - val_loss: 0.6681\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.72285 to 0.66807, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_005_Val_0.668.hdf5\n",
      "Epoch 6/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6676 - val_loss: 0.6106\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.66807 to 0.61057, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_006_Val_0.611.hdf5\n",
      "Epoch 7/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6212 - val_loss: 0.5503\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61057 to 0.55025, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_007_Val_0.550.hdf5\n",
      "Epoch 8/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5747 - val_loss: 0.5176\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55025 to 0.51765, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_008_Val_0.518.hdf5\n",
      "Epoch 9/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5284 - val_loss: 0.4553\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51765 to 0.45528, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_009_Val_0.455.hdf5\n",
      "Epoch 10/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4836 - val_loss: 0.4018\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45528 to 0.40184, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_010_Val_0.402.hdf5\n",
      "Epoch 11/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4438 - val_loss: 0.3621\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.40184 to 0.36211, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_011_Val_0.362.hdf5\n",
      "Epoch 12/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4071 - val_loss: 0.3353\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36211 to 0.33532, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_012_Val_0.335.hdf5\n",
      "Epoch 13/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3753 - val_loss: 0.3074\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33532 to 0.30740, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_013_Val_0.307.hdf5\n",
      "Epoch 14/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3468 - val_loss: 0.2802\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.30740 to 0.28025, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_014_Val_0.280.hdf5\n",
      "Epoch 15/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3191 - val_loss: 0.2666\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.28025 to 0.26655, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_015_Val_0.267.hdf5\n",
      "Epoch 16/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2936 - val_loss: 0.2348\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26655 to 0.23481, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_016_Val_0.235.hdf5\n",
      "Epoch 17/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2717 - val_loss: 0.2091\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.23481 to 0.20909, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_017_Val_0.209.hdf5\n",
      "Epoch 18/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2540 - val_loss: 0.1902\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.20909 to 0.19021, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_018_Val_0.190.hdf5\n",
      "Epoch 19/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2381 - val_loss: 0.1950\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.19021\n",
      "Epoch 20/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2255 - val_loss: 0.1719\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.19021 to 0.17193, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_020_Val_0.172.hdf5\n",
      "Epoch 21/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2165 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.17193 to 0.16956, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_021_Val_0.170.hdf5\n",
      "Epoch 22/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2083 - val_loss: 0.1459\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16956 to 0.14586, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_022_Val_0.146.hdf5\n",
      "Epoch 23/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2009 - val_loss: 0.1316\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.14586 to 0.13164, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_023_Val_0.132.hdf5\n",
      "Epoch 24/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1919 - val_loss: 0.1532\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.13164\n",
      "Epoch 25/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1770 - val_loss: 0.1654\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.13164\n",
      "Epoch 26/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1701 - val_loss: 0.1299\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.13164 to 0.12990, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_026_Val_0.130.hdf5\n",
      "Epoch 27/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1638 - val_loss: 0.1540\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12990\n",
      "Epoch 28/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1565 - val_loss: 0.1217\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.12990 to 0.12168, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_028_Val_0.122.hdf5\n",
      "Epoch 29/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1534 - val_loss: 0.1454\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12168\n",
      "Epoch 30/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1448 - val_loss: 0.1169\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12168 to 0.11692, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_030_Val_0.117.hdf5\n",
      "Epoch 31/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1418 - val_loss: 0.1255\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11692\n",
      "Epoch 32/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1413 - val_loss: 0.0945\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11692 to 0.09448, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_032_Val_0.094.hdf5\n",
      "Epoch 33/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1366 - val_loss: 0.0942\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.09448 to 0.09416, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_033_Val_0.094.hdf5\n",
      "Epoch 34/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1374 - val_loss: 0.1048\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.09416\n",
      "Epoch 35/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1299 - val_loss: 0.0868\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.09416 to 0.08683, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_035_Val_0.087.hdf5\n",
      "Epoch 36/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1305 - val_loss: 0.1324\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08683\n",
      "Epoch 37/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1285 - val_loss: 0.1183\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08683\n",
      "Epoch 38/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1257 - val_loss: 0.0938\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08683\n",
      "Epoch 39/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1238 - val_loss: 0.1027\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08683\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1224 - val_loss: 0.0980\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08683\n",
      "Epoch 41/50\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1208 - val_loss: 0.1008\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08683\n",
      "Epoch 42/50\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1167 - val_loss: 0.0900\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08683\n",
      "Epoch 43/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1175 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08683 to 0.08581, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_043_Val_0.086.hdf5\n",
      "Epoch 44/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1153 - val_loss: 0.0997\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08581\n",
      "Epoch 45/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1124 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08581\n",
      "Epoch 46/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1131 - val_loss: 0.0963\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08581\n",
      "Epoch 47/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1110 - val_loss: 0.1028\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08581\n",
      "Epoch 48/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1103 - val_loss: 0.0877\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08581\n",
      "Epoch 49/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1086 - val_loss: 0.0982\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08581\n",
      "Epoch 50/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1093 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08581\n",
      "Epoch 1/50\n",
      "  6/592 [..............................] - ETA: 6s - loss: 0.9997  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:14:25.833454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:14:32.612369: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 12ms/step - loss: 0.9663 - val_loss: 0.9054\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.90542, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_001_Val_0.905.hdf5\n",
      "Epoch 2/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8596 - val_loss: 0.7991\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.90542 to 0.79910, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_002_Val_0.799.hdf5\n",
      "Epoch 3/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7850 - val_loss: 0.7429\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.79910 to 0.74290, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_003_Val_0.743.hdf5\n",
      "Epoch 4/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7362 - val_loss: 0.7128\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74290 to 0.71279, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_004_Val_0.713.hdf5\n",
      "Epoch 5/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7019 - val_loss: 0.6784\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71279 to 0.67836, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_005_Val_0.678.hdf5\n",
      "Epoch 6/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6669 - val_loss: 0.6487\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67836 to 0.64866, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_006_Val_0.649.hdf5\n",
      "Epoch 7/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6182 - val_loss: 0.5776\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.64866 to 0.57761, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_007_Val_0.578.hdf5\n",
      "Epoch 8/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5716 - val_loss: 0.5332\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.57761 to 0.53319, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_008_Val_0.533.hdf5\n",
      "Epoch 9/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5299 - val_loss: 0.4473\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53319 to 0.44727, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_009_Val_0.447.hdf5\n",
      "Epoch 10/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4889 - val_loss: 0.4324\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.44727 to 0.43243, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_010_Val_0.432.hdf5\n",
      "Epoch 11/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4519 - val_loss: 0.4557\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.43243\n",
      "Epoch 12/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4182 - val_loss: 0.3793\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43243 to 0.37927, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_012_Val_0.379.hdf5\n",
      "Epoch 13/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3893 - val_loss: 0.3567\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.37927 to 0.35673, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_013_Val_0.357.hdf5\n",
      "Epoch 14/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3616 - val_loss: 0.3048\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35673 to 0.30479, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_014_Val_0.305.hdf5\n",
      "Epoch 15/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3376 - val_loss: 0.3277\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.30479\n",
      "Epoch 16/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3138 - val_loss: 0.2644\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.30479 to 0.26442, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_016_Val_0.264.hdf5\n",
      "Epoch 17/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2912 - val_loss: 0.2471\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26442 to 0.24714, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_017_Val_0.247.hdf5\n",
      "Epoch 18/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2693 - val_loss: 0.2406\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24714 to 0.24057, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_018_Val_0.241.hdf5\n",
      "Epoch 19/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2519 - val_loss: 0.2139\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.24057 to 0.21393, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_019_Val_0.214.hdf5\n",
      "Epoch 20/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2352 - val_loss: 0.1812\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21393 to 0.18121, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_020_Val_0.181.hdf5\n",
      "Epoch 21/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2200 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.18121 to 0.17405, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_021_Val_0.174.hdf5\n",
      "Epoch 22/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2020 - val_loss: 0.1692\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.17405 to 0.16918, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_022_Val_0.169.hdf5\n",
      "Epoch 23/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1970 - val_loss: 0.1424\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16918 to 0.14238, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_023_Val_0.142.hdf5\n",
      "Epoch 24/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1757 - val_loss: 0.1281\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14238 to 0.12811, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_024_Val_0.128.hdf5\n",
      "Epoch 25/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1679 - val_loss: 0.1267\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.12811 to 0.12675, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_025_Val_0.127.hdf5\n",
      "Epoch 26/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1534 - val_loss: 0.1141\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12675 to 0.11406, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_026_Val_0.114.hdf5\n",
      "Epoch 27/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1508 - val_loss: 0.1035\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11406 to 0.10349, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_027_Val_0.103.hdf5\n",
      "Epoch 28/50\n",
      "592/592 [==============================] - 7s 13ms/step - loss: 0.1467 - val_loss: 0.1028\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.10349 to 0.10279, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_028_Val_0.103.hdf5\n",
      "Epoch 29/50\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.1349 - val_loss: 0.0903\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.10279 to 0.09028, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_029_Val_0.090.hdf5\n",
      "Epoch 30/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1298 - val_loss: 0.0924\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.09028\n",
      "Epoch 31/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1244 - val_loss: 0.0903\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.09028 to 0.09027, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_031_Val_0.090.hdf5\n",
      "Epoch 32/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1245 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.09027\n",
      "Epoch 33/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1175 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.09027 to 0.08584, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_033_Val_0.086.hdf5\n",
      "Epoch 34/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1167 - val_loss: 0.0803\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08584 to 0.08026, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_034_Val_0.080.hdf5\n",
      "Epoch 35/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1159 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08026\n",
      "Epoch 36/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1128 - val_loss: 0.0806\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08026\n",
      "Epoch 37/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1111 - val_loss: 0.0781\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08026 to 0.07811, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_037_Val_0.078.hdf5\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1084 - val_loss: 0.0790\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07811\n",
      "Epoch 39/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1119 - val_loss: 0.0792\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07811\n",
      "Epoch 40/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1063 - val_loss: 0.0785\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07811\n",
      "Epoch 41/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1039 - val_loss: 0.0748\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.07811 to 0.07484, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_041_Val_0.075.hdf5\n",
      "Epoch 42/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1055 - val_loss: 0.0799\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07484\n",
      "Epoch 43/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1043 - val_loss: 0.0751\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07484\n",
      "Epoch 44/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1050 - val_loss: 0.0851\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07484\n",
      "Epoch 45/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1015 - val_loss: 0.0824\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07484\n",
      "Epoch 46/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1012 - val_loss: 0.0870\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07484\n",
      "Epoch 47/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1068 - val_loss: 0.0730\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.07484 to 0.07297, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_047_Val_0.073.hdf5\n",
      "Epoch 48/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1006 - val_loss: 0.0825\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07297\n",
      "Epoch 49/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0996 - val_loss: 0.0774\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07297\n",
      "Epoch 50/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0975 - val_loss: 0.0847\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07297\n",
      "Epoch 1/50\n",
      "  6/591 [..............................] - ETA: 6s - loss: 0.9998  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:20:16.663754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - ETA: 0s - loss: 0.9699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:20:23.232171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 7s 11ms/step - loss: 0.9699 - val_loss: 0.9154\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.91535, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_001_Val_0.915.hdf5\n",
      "Epoch 2/50\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.8769 - val_loss: 0.8498\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.91535 to 0.84982, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_002_Val_0.850.hdf5\n",
      "Epoch 3/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.8169 - val_loss: 0.8108\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.84982 to 0.81078, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_003_Val_0.811.hdf5\n",
      "Epoch 4/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.7701 - val_loss: 0.7662\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.81078 to 0.76617, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_004_Val_0.766.hdf5\n",
      "Epoch 5/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.7173 - val_loss: 0.6968\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.76617 to 0.69683, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_005_Val_0.697.hdf5\n",
      "Epoch 6/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.6635 - val_loss: 0.6261\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69683 to 0.62613, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_006_Val_0.626.hdf5\n",
      "Epoch 7/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.6142 - val_loss: 0.5774\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62613 to 0.57744, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_007_Val_0.577.hdf5\n",
      "Epoch 8/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.5681 - val_loss: 0.5482\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.57744 to 0.54818, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_008_Val_0.548.hdf5\n",
      "Epoch 9/50\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.5236 - val_loss: 0.4895\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.54818 to 0.48948, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_009_Val_0.489.hdf5\n",
      "Epoch 10/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.4804 - val_loss: 0.4453\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48948 to 0.44528, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_010_Val_0.445.hdf5\n",
      "Epoch 11/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.4398 - val_loss: 0.4232\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44528 to 0.42321, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_011_Val_0.423.hdf5\n",
      "Epoch 12/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.4032 - val_loss: 0.3824\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42321 to 0.38238, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_012_Val_0.382.hdf5\n",
      "Epoch 13/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.3689 - val_loss: 0.3424\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.38238 to 0.34240, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_013_Val_0.342.hdf5\n",
      "Epoch 14/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.3391 - val_loss: 0.3057\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34240 to 0.30571, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_014_Val_0.306.hdf5\n",
      "Epoch 15/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.3144 - val_loss: 0.2618\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.30571 to 0.26178, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_015_Val_0.262.hdf5\n",
      "Epoch 16/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2865 - val_loss: 0.2563\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26178 to 0.25634, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_016_Val_0.256.hdf5\n",
      "Epoch 17/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2688 - val_loss: 0.2262\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25634 to 0.22616, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_017_Val_0.226.hdf5\n",
      "Epoch 18/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2467 - val_loss: 0.2369\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.22616\n",
      "Epoch 19/50\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.2280 - val_loss: 0.1973\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22616 to 0.19726, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_019_Val_0.197.hdf5\n",
      "Epoch 20/50\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.2179 - val_loss: 0.1787\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.19726 to 0.17869, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_020_Val_0.179.hdf5\n",
      "Epoch 21/50\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.2049 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.17869 to 0.16659, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_021_Val_0.167.hdf5\n",
      "Epoch 22/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1939 - val_loss: 0.1668\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16659\n",
      "Epoch 23/50\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.1866 - val_loss: 0.2092\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16659\n",
      "Epoch 24/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1786 - val_loss: 0.1517\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.16659 to 0.15173, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_024_Val_0.152.hdf5\n",
      "Epoch 25/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1723 - val_loss: 0.1313\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.15173 to 0.13135, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_025_Val_0.131.hdf5\n",
      "Epoch 26/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1666 - val_loss: 0.1332\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.13135\n",
      "Epoch 27/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1616 - val_loss: 0.1294\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.13135 to 0.12944, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_027_Val_0.129.hdf5\n",
      "Epoch 28/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1560 - val_loss: 0.1266\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.12944 to 0.12656, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_028_Val_0.127.hdf5\n",
      "Epoch 29/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1511 - val_loss: 0.1493\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.12656\n",
      "Epoch 30/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1483 - val_loss: 0.1148\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12656 to 0.11483, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_030_Val_0.115.hdf5\n",
      "Epoch 31/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1467 - val_loss: 0.1232\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11483\n",
      "Epoch 32/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1432 - val_loss: 0.1084\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11483 to 0.10841, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_032_Val_0.108.hdf5\n",
      "Epoch 33/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1415 - val_loss: 0.1187\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10841\n",
      "Epoch 34/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1328 - val_loss: 0.1239\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10841\n",
      "Epoch 35/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1352 - val_loss: 0.1031\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.10841 to 0.10308, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_035_Val_0.103.hdf5\n",
      "Epoch 36/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1318 - val_loss: 0.1072\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.10308\n",
      "Epoch 37/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1305 - val_loss: 0.1553\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.10308\n",
      "Epoch 38/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1266 - val_loss: 0.1076\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10308\n",
      "Epoch 39/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1222 - val_loss: 0.1123\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10308\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1195 - val_loss: 0.1058\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10308\n",
      "Epoch 41/50\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1173 - val_loss: 0.0996\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.10308 to 0.09956, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_041_Val_0.100.hdf5\n",
      "Epoch 42/50\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1170 - val_loss: 0.1296\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.09956\n",
      "Epoch 43/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1137 - val_loss: 0.0964\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.09956 to 0.09639, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_043_Val_0.096.hdf5\n",
      "Epoch 44/50\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1113 - val_loss: 0.1011\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.09639\n",
      "Epoch 45/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1125 - val_loss: 0.1009\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.09639\n",
      "Epoch 46/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1078 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.09639 to 0.08812, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_046_Val_0.088.hdf5\n",
      "Epoch 47/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1064 - val_loss: 0.0992\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08812\n",
      "Epoch 48/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1069 - val_loss: 0.1024\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08812\n",
      "Epoch 49/50\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1058 - val_loss: 0.1007\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08812\n",
      "Epoch 50/50\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1066 - val_loss: 0.1040\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08812\n",
      "Epoch 1/50\n",
      "  6/592 [..............................] - ETA: 6s - loss: 0.9997  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:25:49.785555: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:25:56.209762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.9727 - val_loss: 0.9419\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.94187, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_001_Val_0.942.hdf5\n",
      "Epoch 2/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8648 - val_loss: 0.8074\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.94187 to 0.80738, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_002_Val_0.807.hdf5\n",
      "Epoch 3/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7856 - val_loss: 0.7441\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80738 to 0.74407, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_003_Val_0.744.hdf5\n",
      "Epoch 4/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7350 - val_loss: 0.7018\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74407 to 0.70176, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_004_Val_0.702.hdf5\n",
      "Epoch 5/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7001 - val_loss: 0.6636\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.70176 to 0.66363, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_005_Val_0.664.hdf5\n",
      "Epoch 6/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6602 - val_loss: 0.6185\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.66363 to 0.61854, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_006_Val_0.619.hdf5\n",
      "Epoch 7/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6154 - val_loss: 0.5698\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.61854 to 0.56983, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_007_Val_0.570.hdf5\n",
      "Epoch 8/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5709 - val_loss: 0.5284\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56983 to 0.52837, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_008_Val_0.528.hdf5\n",
      "Epoch 9/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5298 - val_loss: 0.4869\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.52837 to 0.48686, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_009_Val_0.487.hdf5\n",
      "Epoch 10/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4920 - val_loss: 0.4216\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48686 to 0.42158, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_010_Val_0.422.hdf5\n",
      "Epoch 11/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4556 - val_loss: 0.4130\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.42158 to 0.41301, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_011_Val_0.413.hdf5\n",
      "Epoch 12/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4223 - val_loss: 0.3758\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.41301 to 0.37579, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_012_Val_0.376.hdf5\n",
      "Epoch 13/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3923 - val_loss: 0.3452\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.37579 to 0.34517, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_013_Val_0.345.hdf5\n",
      "Epoch 14/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3659 - val_loss: 0.3114\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34517 to 0.31136, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_014_Val_0.311.hdf5\n",
      "Epoch 15/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3420 - val_loss: 0.2707\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31136 to 0.27069, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_015_Val_0.271.hdf5\n",
      "Epoch 16/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3141 - val_loss: 0.2305\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27069 to 0.23046, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_016_Val_0.230.hdf5\n",
      "Epoch 17/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2951 - val_loss: 0.2453\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23046\n",
      "Epoch 18/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2715 - val_loss: 0.2046\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.23046 to 0.20460, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_018_Val_0.205.hdf5\n",
      "Epoch 19/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2545 - val_loss: 0.2287\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20460\n",
      "Epoch 20/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2392 - val_loss: 0.2175\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20460\n",
      "Epoch 21/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2235 - val_loss: 0.1646\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.20460 to 0.16459, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_021_Val_0.165.hdf5\n",
      "Epoch 22/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2080 - val_loss: 0.1552\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16459 to 0.15524, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_022_Val_0.155.hdf5\n",
      "Epoch 23/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1999 - val_loss: 0.1414\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15524 to 0.14135, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_023_Val_0.141.hdf5\n",
      "Epoch 24/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1843 - val_loss: 0.1304\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14135 to 0.13045, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_024_Val_0.130.hdf5\n",
      "Epoch 25/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1786 - val_loss: 0.1229\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.13045 to 0.12288, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_025_Val_0.123.hdf5\n",
      "Epoch 26/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1721 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12288\n",
      "Epoch 27/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1646 - val_loss: 0.1148\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.12288 to 0.11483, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_027_Val_0.115.hdf5\n",
      "Epoch 28/50\n",
      "592/592 [==============================] - 5s 8ms/step - loss: 0.1624 - val_loss: 0.1107\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.11483 to 0.11068, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_028_Val_0.111.hdf5\n",
      "Epoch 29/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1559 - val_loss: 0.1016\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11068 to 0.10160, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_029_Val_0.102.hdf5\n",
      "Epoch 30/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1520 - val_loss: 0.1088\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10160\n",
      "Epoch 31/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1493 - val_loss: 0.1058\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10160\n",
      "Epoch 32/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1506 - val_loss: 0.1089\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10160\n",
      "Epoch 33/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1417 - val_loss: 0.0910\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.10160 to 0.09098, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_033_Val_0.091.hdf5\n",
      "Epoch 34/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1367 - val_loss: 0.1136\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.09098\n",
      "Epoch 35/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1376 - val_loss: 0.1220\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.09098\n",
      "Epoch 36/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1357 - val_loss: 0.0879\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.09098 to 0.08786, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_036_Val_0.088.hdf5\n",
      "Epoch 37/50\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.1334 - val_loss: 0.0853\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08786 to 0.08533, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_037_Val_0.085.hdf5\n",
      "Epoch 38/50\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.1282 - val_loss: 0.0965\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08533\n",
      "Epoch 39/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1273 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08533\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1238 - val_loss: 0.0963\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08533\n",
      "Epoch 41/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1251 - val_loss: 0.1019\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08533\n",
      "Epoch 42/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1209 - val_loss: 0.0920\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08533\n",
      "Epoch 43/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1218 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08533\n",
      "Epoch 44/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1168 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08533\n",
      "Epoch 45/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1180 - val_loss: 0.0886\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08533\n",
      "Epoch 46/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1157 - val_loss: 0.0793\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08533 to 0.07927, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_046_Val_0.079.hdf5\n",
      "Epoch 47/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1157 - val_loss: 0.0883\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07927\n",
      "Epoch 48/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1134 - val_loss: 0.0784\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07927 to 0.07840, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_048_Val_0.078.hdf5\n",
      "Epoch 49/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1135 - val_loss: 0.0850\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07840\n",
      "Epoch 50/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1111 - val_loss: 0.0827\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07840\n",
      "Epoch 1/50\n",
      "  6/592 [..............................] - ETA: 6s - loss: 0.9999  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:31:39.399475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:31:46.013346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.9698 - val_loss: 0.9302\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93024, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_001_Val_0.930.hdf5\n",
      "Epoch 2/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8587 - val_loss: 0.8147\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93024 to 0.81473, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_002_Val_0.815.hdf5\n",
      "Epoch 3/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7851 - val_loss: 0.7549\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81473 to 0.75493, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_003_Val_0.755.hdf5\n",
      "Epoch 4/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7358 - val_loss: 0.7197\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.75493 to 0.71974, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_004_Val_0.720.hdf5\n",
      "Epoch 5/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6930 - val_loss: 0.6874\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71974 to 0.68743, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_005_Val_0.687.hdf5\n",
      "Epoch 6/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6489 - val_loss: 0.6264\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68743 to 0.62635, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_006_Val_0.626.hdf5\n",
      "Epoch 7/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6041 - val_loss: 0.5875\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62635 to 0.58745, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_007_Val_0.587.hdf5\n",
      "Epoch 8/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5605 - val_loss: 0.5512\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.58745 to 0.55115, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_008_Val_0.551.hdf5\n",
      "Epoch 9/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5175 - val_loss: 0.5152\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55115 to 0.51524, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_009_Val_0.515.hdf5\n",
      "Epoch 10/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4782 - val_loss: 0.4753\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.51524 to 0.47532, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_010_Val_0.475.hdf5\n",
      "Epoch 11/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4420 - val_loss: 0.4314\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.47532 to 0.43144, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_011_Val_0.431.hdf5\n",
      "Epoch 12/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4092 - val_loss: 0.4143\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43144 to 0.41427, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_012_Val_0.414.hdf5\n",
      "Epoch 13/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3786 - val_loss: 0.3872\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.41427 to 0.38717, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_013_Val_0.387.hdf5\n",
      "Epoch 14/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3535 - val_loss: 0.3479\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.38717 to 0.34794, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_014_Val_0.348.hdf5\n",
      "Epoch 15/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3270 - val_loss: 0.3322\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34794 to 0.33224, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_015_Val_0.332.hdf5\n",
      "Epoch 16/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3022 - val_loss: 0.3241\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33224 to 0.32414, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_016_Val_0.324.hdf5\n",
      "Epoch 17/50\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.2803 - val_loss: 0.2914\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.32414 to 0.29136, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_017_Val_0.291.hdf5\n",
      "Epoch 18/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2609 - val_loss: 0.2624\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.29136 to 0.26236, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_018_Val_0.262.hdf5\n",
      "Epoch 19/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2462 - val_loss: 0.2521\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.26236 to 0.25214, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_019_Val_0.252.hdf5\n",
      "Epoch 20/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2310 - val_loss: 0.2267\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.25214 to 0.22667, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_020_Val_0.227.hdf5\n",
      "Epoch 21/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2186 - val_loss: 0.2231\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.22667 to 0.22312, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_021_Val_0.223.hdf5\n",
      "Epoch 22/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2058 - val_loss: 0.2282\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.22312\n",
      "Epoch 23/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1943 - val_loss: 0.2230\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22312 to 0.22295, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_023_Val_0.223.hdf5\n",
      "Epoch 24/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1810 - val_loss: 0.1772\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.22295 to 0.17722, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_024_Val_0.177.hdf5\n",
      "Epoch 25/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1698 - val_loss: 0.1962\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17722\n",
      "Epoch 26/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1591 - val_loss: 0.1884\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.17722\n",
      "Epoch 27/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1523 - val_loss: 0.1603\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.17722 to 0.16029, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_027_Val_0.160.hdf5\n",
      "Epoch 28/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1465 - val_loss: 0.1482\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.16029 to 0.14821, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_028_Val_0.148.hdf5\n",
      "Epoch 29/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1426 - val_loss: 0.1499\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14821\n",
      "Epoch 30/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1352 - val_loss: 0.1416\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.14821 to 0.14160, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_030_Val_0.142.hdf5\n",
      "Epoch 31/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1303 - val_loss: 0.1650\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14160\n",
      "Epoch 32/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1297 - val_loss: 0.1483\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14160\n",
      "Epoch 33/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1210 - val_loss: 0.1530\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.14160\n",
      "Epoch 34/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1190 - val_loss: 0.1311\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.14160 to 0.13106, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_034_Val_0.131.hdf5\n",
      "Epoch 35/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1170 - val_loss: 0.1288\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.13106 to 0.12884, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_035_Val_0.129.hdf5\n",
      "Epoch 36/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1159 - val_loss: 0.1282\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.12884 to 0.12820, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_036_Val_0.128.hdf5\n",
      "Epoch 37/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1100 - val_loss: 0.1398\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.12820\n",
      "Epoch 38/50\n",
      "592/592 [==============================] - 7s 13ms/step - loss: 0.1093 - val_loss: 0.1297\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.12820\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 8s 13ms/step - loss: 0.1048 - val_loss: 0.1368\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.12820\n",
      "Epoch 40/50\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.1067 - val_loss: 0.1292\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.12820\n",
      "Epoch 41/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1047 - val_loss: 0.1396\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.12820\n",
      "Epoch 42/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1024 - val_loss: 0.1317\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.12820\n",
      "Epoch 43/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0982 - val_loss: 0.1128\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.12820 to 0.11281, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_043_Val_0.113.hdf5\n",
      "Epoch 44/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1022 - val_loss: 0.1089\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.11281 to 0.10893, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_044_Val_0.109.hdf5\n",
      "Epoch 45/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0990 - val_loss: 0.1157\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10893\n",
      "Epoch 46/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0993 - val_loss: 0.1203\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10893\n",
      "Epoch 47/50\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0982 - val_loss: 0.1205\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10893\n",
      "Epoch 48/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0971 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.10893 to 0.10610, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_048_Val_0.106.hdf5\n",
      "Epoch 49/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0937 - val_loss: 0.1119\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10610\n",
      "Epoch 50/50\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0939 - val_loss: 0.1272\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10610\n"
     ]
    }
   ],
   "source": [
    "\n",
    "year = 2013\n",
    "for train_x, train_y, valid_x, valid_y in zip(train_x_lst, train_y_lst, val_x_lst, val_y_lst):\n",
    "\n",
    "    model = make_model()\n",
    "    model.compile(optimizer='adam', loss = n_mae)\n",
    "    #model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "    #model.summary()\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode = 'min' , patience = 20, verbose = 1)\n",
    "    folder_path = './Models/DNN_temp/valid_year_{}'.format(year)\n",
    "    file_path = folder_path + '/Epoch_{epoch:03d}_Val_{val_loss:.3f}.hdf5'\n",
    "    mc = ModelCheckpoint(file_path, monitor='val_loss', mode='min',verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "    history = model.fit(train_x, train_y, epochs = 80, batch_size = 128, \\\n",
    "                        shuffle= True, validation_data = (valid_x, valid_y), \\\n",
    "                        verbose = 1, callbacks = [mc, es])\n",
    "    \n",
    "    year += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'train loss')\n",
    "plt.plot(history.history['val_loss'], label = 'validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2013 = make_model()\n",
    "model_2013.load_weights('./Models/DNN_temp/valid_year_2013/Epoch_048_Val_0.090.hdf5')\n",
    "\n",
    "model_2014 = make_model()\n",
    "model_2014.load_weights('./Models/DNN_temp/valid_year_2014/Epoch_043_Val_0.086.hdf5')\n",
    "\n",
    "model_2015 = make_model()\n",
    "model_2015.load_weights('./Models/DNN_temp/valid_year_2015/Epoch_047_Val_0.073.hdf5')\n",
    "\n",
    "model_2016 = make_model()\n",
    "model_2016.load_weights('./Models/DNN_temp/valid_year_2016/Epoch_046_Val_0.088.hdf5')\n",
    "\n",
    "model_2017 = make_model()\n",
    "model_2017.load_weights('./Models/DNN_temp/valid_year_2017/Epoch_048_Val_0.078.hdf5')\n",
    "\n",
    "model_2018 = make_model()\n",
    "model_2018.load_weights('./Models/DNN_temp/valid_year_2018/Epoch_048_Val_0.106.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_2013, model_2014, model_2015, model_2016, model_2017, model_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train_x, label = train_y)\n",
    "dval = xgb.DMatrix(data=val_x, label = val_y)\n",
    "wlist = [(dtrain, 'train'), (dval,'eval')]\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'metric':'mae', \n",
    "    'seed':42\n",
    "}\n",
    " \n",
    "\n",
    "model = xgb.train( params, dtrain, 500, evals=wlist, verbose_eval=20, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./Submission/test.csv')\n",
    "submission = pd.read_csv('./Submission/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자|시간|구분</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05 A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자|시간|구분\n",
       "0  2019-01-01 01 A\n",
       "1  2019-01-01 02 A\n",
       "2  2019-01-01 03 A\n",
       "3  2019-01-01 04 A\n",
       "4  2019-01-01 05 A"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자|시간|구분</th>\n",
       "      <th>공급량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자|시간|구분  공급량\n",
       "0  2019-01-01 01 A    0\n",
       "1  2019-01-01 02 A    0\n",
       "2  2019-01-01 03 A    0\n",
       "3  2019-01-01 04 A    0\n",
       "4  2019-01-01 05 A    0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime'] = test['일자|시간|구분'].str.split(' ').str[0]\n",
    "test['hour'] = test['일자|시간|구분'].str.split(' ').str[1].astype(int)\n",
    "test['company'] = test['일자|시간|구분'].str.split(' ').str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "test['year'] = test['datetime'].dt.year\n",
    "test['month'] = test['datetime'].dt.month\n",
    "test['day'] = test['datetime'].dt.day\n",
    "test['weekday'] = test['datetime'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['company'] = test['company'].map(company_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자|시간|구분</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자|시간|구분   datetime  hour  company  year  month  day  weekday\n",
       "0  2019-01-01 01 A 2019-01-01     1        0  2019      1    1        1\n",
       "1  2019-01-01 02 A 2019-01-01     2        0  2019      1    1        1\n",
       "2  2019-01-01 03 A 2019-01-01     3        0  2019      1    1        1\n",
       "3  2019-01-01 04 A 2019-01-01     4        0  2019      1    1        1\n",
       "4  2019-01-01 05 A 2019-01-01     5        0  2019      1    1        1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          일자|시간|구분   datetime  hour  company  year  month  day  weekday  \\\n",
      "0  2019-01-01 01 A 2019-01-01     1        0  2019      1    1        1   \n",
      "1  2019-01-01 02 A 2019-01-01     2        0  2019      1    1        1   \n",
      "2  2019-01-01 03 A 2019-01-01     3        0  2019      1    1        1   \n",
      "3  2019-01-01 04 A 2019-01-01     4        0  2019      1    1        1   \n",
      "4  2019-01-01 05 A 2019-01-01     5        0  2019      1    1        1   \n",
      "\n",
      "   temperature  \n",
      "0    -2.683333  \n",
      "1    -3.116667  \n",
      "2    -3.483333  \n",
      "3    -3.716667  \n",
      "4    -4.050000  \n",
      "              일자|시간|구분   datetime  hour  company  year  month  day  weekday  \\\n",
      "15115  2019-03-31 20 H 2019-03-31    20        6  2019      3   31        6   \n",
      "15116  2019-03-31 21 H 2019-03-31    21        6  2019      3   31        6   \n",
      "15117  2019-03-31 22 H 2019-03-31    22        6  2019      3   31        6   \n",
      "15118  2019-03-31 23 H 2019-03-31    23        6  2019      3   31        6   \n",
      "15119  2019-03-31 24 H 2019-03-31    24        6  2019      3   31        6   \n",
      "\n",
      "       temperature  \n",
      "15115    12.883333  \n",
      "15116    11.800000  \n",
      "15117    11.083333  \n",
      "15118    10.450000  \n",
      "15119     9.950000  \n"
     ]
    }
   ],
   "source": [
    "test_combined = pd.merge(test, daily_temp, how = 'left', left_on = ['month', 'day', 'hour'], right_on = ['month', 'day', 'hour'])\n",
    "\n",
    "print(test_combined.iloc[:5])\n",
    "print(test_combined.iloc[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68333333,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ],\n",
       "       [-3.11666667,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         2.        ],\n",
       "       [-3.48333333,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         3.        ],\n",
       "       [-3.71666667,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         4.        ],\n",
       "       [-4.05      ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         5.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = test_combined[features]\n",
    "\n",
    "test_x = test_x.values\n",
    "\n",
    "#test_x = x_scaler.transform(test_x)\n",
    "test_x[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:47.493773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1883.8281]\n",
      " [1664.449 ]\n",
      " [1596.1917]\n",
      " [1690.7303]\n",
      " [1831.1443]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:48.187852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1800.4664]\n",
      " [1651.8857]\n",
      " [1565.0012]\n",
      " [1657.2333]\n",
      " [1787.57  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:48.882474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1895.863 ]\n",
      " [1607.7179]\n",
      " [1525.3042]\n",
      " [1595.7412]\n",
      " [1681.7589]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:49.565560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1781.9425]\n",
      " [1615.4392]\n",
      " [1547.5463]\n",
      " [1652.0424]\n",
      " [1852.2092]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:50.262651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1898.8175]\n",
      " [1695.0132]\n",
      " [1619.2999]\n",
      " [1727.7306]\n",
      " [1922.3292]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:50.980368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1916.5156]\n",
      " [1631.5621]\n",
      " [1569.4972]\n",
      " [1688.542 ]\n",
      " [1815.7892]]\n"
     ]
    }
   ],
   "source": [
    "pred_lst = []\n",
    "for model in models:\n",
    "    pred = model.predict(test_x)\n",
    "    print(pred[:5])\n",
    "    pred_lst.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1862.9054, 1644.3447, 1570.4735, 1668.67  , 1815.1334],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.concatenate(pred_lst, axis = 1)\n",
    "preds[:5]\n",
    "\n",
    "preds_combined = np.mean(preds, axis = 1)\n",
    "preds_combined[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['공급량'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./Submission/dnn_temp_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
