{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>company</th>\n",
       "      <th>gas</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2497.129</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2363.265</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2258.505</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2243.969</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2344.105</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361478</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>181.907</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361479</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>166.607</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361480</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>173.503</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361481</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>191.135</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361482</th>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>219.185</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90883 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  hour  company       gas  year  month  day  weekday\n",
       "0      2013-01-01     1        0  2497.129  2013      1    1        1\n",
       "1      2013-01-01     2        0  2363.265  2013      1    1        1\n",
       "2      2013-01-01     3        0  2258.505  2013      1    1        1\n",
       "3      2013-01-01     4        0  2243.969  2013      1    1        1\n",
       "4      2013-01-01     5        0  2344.105  2013      1    1        1\n",
       "...           ...   ...      ...       ...   ...    ...  ...      ...\n",
       "361478 2018-03-31    15        6   181.907  2018      3   31        5\n",
       "361479 2018-03-31    16        6   166.607  2018      3   31        5\n",
       "361480 2018-03-31    17        6   173.503  2018      3   31        5\n",
       "361481 2018-03-31    18        6   191.135  2018      3   31        5\n",
       "361482 2018-03-31    19        6   219.185  2018      3   31        5\n",
       "\n",
       "[90883 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pd.read_csv('./Data/한국가스공사_시간별 공급량_20181231.csv', encoding='cp949')\n",
    "total.columns = ['date', 'hour', 'company', 'gas']\n",
    "\n",
    "\n",
    "companys = total['company'].unique()\n",
    "company_map = dict()\n",
    "for i, company in enumerate(companys):\n",
    "    company_map[company] = i\n",
    "total['company'] = total['company'].map(company_map)\n",
    "total['date'] = pd.to_datetime(total['date'])\n",
    "total['year'] = total['date'].dt.year\n",
    "total['month'] = total['date'].dt.month\n",
    "total['day'] = total['date'].dt.day\n",
    "total['weekday'] = total['date'].dt.weekday\n",
    "\n",
    "\n",
    "total = total[total['month'].isin([1,2,3])]\n",
    "total.head(-5)\n",
    "#total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'G': 5, 'H': 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8784, 7)\n",
      "(8756, 7)\n",
      "(8759, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temps = []\n",
    "for year in range(2013, 2019):\n",
    "    temp = pd.read_csv(f'./Data/temperature_{year}.csv', encoding='cp949')\n",
    "    #temp.columns = header\n",
    "    temp = temp[['일시', '기온(°C)']]\n",
    "    temp.columns = ['datetime', 'temperature']\n",
    "    temp['datetime'] = pd.to_datetime(temp['datetime'])\n",
    "    temp['year'] = temp['datetime'].dt.year\n",
    "    temp['month'] = temp['datetime'].dt.month\n",
    "    temp['day'] = temp['datetime'].dt.day\n",
    "    temp['weekday'] = temp['datetime'].dt.weekday\n",
    "    temp['hour'] = temp['datetime'].dt.hour + 1\n",
    "    print(temp.shape)\n",
    "    temps.append(temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             datetime  temperature  year  month  day  weekday  hour\n",
      "0 2014-12-31 23:00:00         -6.2  2014     12   31        2    24\n",
      "1 2015-01-01 01:00:00         -7.4  2015      1    1        3     2\n",
      "2 2015-01-01 02:00:00         -8.0  2015      1    1        3     3\n",
      "3 2015-01-01 03:00:00         -8.4  2015      1    1        3     4\n",
      "4 2015-01-01 04:00:00         -8.8  2015      1    1        3     5\n",
      "             datetime  temperature  year  month  day  weekday  hour\n",
      "0 2015-01-01 00:00:00         -6.2  2015      1    1        3     1\n",
      "1 2015-01-01 01:00:00         -7.4  2015      1    1        3     2\n",
      "2 2015-01-01 02:00:00         -8.0  2015      1    1        3     3\n",
      "3 2015-01-01 03:00:00         -8.4  2015      1    1        3     4\n",
      "4 2015-01-01 04:00:00         -8.8  2015      1    1        3     5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/woojaebyun/miniforge3/envs/mlp/lib/python3.8/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# interpolation for 2015\n",
    "\n",
    "print(temps[2].head())\n",
    "temps[2]['datetime'].iloc[0] = pd.to_datetime(\"2015-01-01 00:00:00\")\n",
    "temps[2]['year'].iloc[0] = 2015\n",
    "temps[2]['month'].iloc[0] = 1\n",
    "temps[2]['day'].iloc[0] = 1\n",
    "temps[2]['weekday'].iloc[0] = 3\n",
    "temps[2]['hour'].iloc[0] = 1\n",
    "\n",
    "print(temps[2].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6449 6831 6832 6833]\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6448 2017-09-26 16:00:00         30.4  2017      9   26        1    17\n",
      "6449 2017-09-26 18:00:00         27.9  2017      9   26        1    19\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6829 2017-10-12 14:00:00         13.7  2017     10   12        3    15\n",
      "6830 2017-10-12 18:00:00         12.8  2017     10   12        3    19\n",
      "6831 2017-10-12 19:00:00         11.5  2017     10   12        3    20\n",
      "6832 2017-10-12 20:00:00         10.6  2017     10   12        3    21\n",
      "6833 2017-10-12 21:00:00         10.2  2017     10   12        3    22\n",
      "6834 2017-10-12 22:00:00          9.7  2017     10   12        3    23\n",
      "29.15\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6448 2017-09-26 16:00:00        30.40  2017      9   26        1    17\n",
      "6449 2017-09-26 17:00:00        29.15  2017      9   26        1    18\n",
      "6450 2017-09-26 18:00:00        27.90  2017      9   26        1    19\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "6829 2017-10-12 13:00:00         13.5  2017     10   12        3    14\n",
      "6830 2017-10-12 14:00:00         13.7  2017     10   12        3    15\n",
      "6831 2017-10-12 15:00:00         13.5  2017     10   12        3    16\n",
      "6832 2017-10-12 16:00:00         13.3  2017     10   12        3    17\n",
      "6833 2017-10-12 17:00:00         13.1  2017     10   12        3    18\n",
      "6834 2017-10-12 18:00:00         12.8  2017     10   12        3    19\n",
      "6835 2017-10-12 19:00:00         11.5  2017     10   12        3    20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/y3tvnwx10nqc9qqg0b1wb7wr0000gn/T/ipykernel_86419/2936941575.py:3: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  missing_indices = pd.isnull(temps[-2].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0]\n"
     ]
    }
   ],
   "source": [
    "# interpolation for 2017\n",
    "\n",
    "missing_indices = pd.isnull(temps[-2].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0]\n",
    "print(missing_indices)\n",
    "\n",
    "print(temps[-2].iloc[6448:6450])    \n",
    "print(temps[-2].iloc[6829:6835])\n",
    "\n",
    "calc_temp = temps[-2]['temperature'].iloc[6448:6450].mean()\n",
    "print(calc_temp)\n",
    "line = pd.DataFrame({\"datetime\": pd.to_datetime(\"2017-09-26 17:00:00\"), 'temperature': calc_temp, \"year\": 2017, 'month': 9, 'day':26, \\\n",
    "                  'weekday':1, 'hour': 18}, index=[6449] )\n",
    "\n",
    "\n",
    "lines = \\\n",
    "pd.DataFrame({\"datetime\": [pd.to_datetime(\"2017-10-12 15:00:00\"), pd.to_datetime(\"2017-10-12 16:00:00\"), pd.to_datetime(\"2017-10-12 17:00:00\")], \\\n",
    "              'temperature': [13.5, 13.3, 13.1], \\\n",
    "              \"year\": [2017, 2017, 2017], 'month': [10, 10, 10], \\\n",
    "              'day':[12,12,12], 'weekday':[3,3,3], 'hour': [16,17,18]}, \\\n",
    "              index=[6830, 6831, 6832] )\n",
    "\n",
    "\n",
    "\n",
    "temps[-2] = pd.concat([temps[-2].iloc[:6449], line, temps[-2].iloc[6449:6830], lines, temps[-2].iloc[6830:]]).reset_index(drop=True)\n",
    "\n",
    "print(temps[-2].iloc[6448:6451])    \n",
    "print(temps[-2].iloc[6829:6836])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7986]\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "7985 2018-11-29 17:00:00          5.8  2018     11   29        3    18\n",
      "7986 2018-11-29 19:00:00          5.2  2018     11   29        3    20\n",
      "5.5\n",
      "                datetime  temperature  year  month  day  weekday  hour\n",
      "7985 2018-11-29 17:00:00          5.8  2018     11   29        3    18\n",
      "7986 2018-11-29 18:00:00          5.5  2018     11   29        3    19\n",
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8760, 7)\n",
      "(8784, 7)\n",
      "(8760, 7)\n",
      "(8760, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/y3tvnwx10nqc9qqg0b1wb7wr0000gn/T/ipykernel_86419/2492857734.py:3: FutureWarning: 'base' in .resample() and in Grouper() is deprecated.\n",
      "The new arguments that you should use are 'offset' or 'origin'.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", base=2)\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> df.resample(freq=\"3s\", offset=\"2s\")\n",
      "\n",
      "  print(pd.isnull(temps[-1].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0])\n"
     ]
    }
   ],
   "source": [
    "# interpolation for 2018\n",
    "\n",
    "print(pd.isnull(temps[-1].resample('1H', on='datetime', base=1).mean()).any(1).to_numpy().nonzero()[0])\n",
    "print(temps[-1].iloc[7985:7987])\n",
    "\n",
    "calc_temp = temps[-1]['temperature'].iloc[7985:7987].mean()\n",
    "print(calc_temp)\n",
    "line = pd.DataFrame({\"datetime\": pd.to_datetime(\"2018-11-29 18:00:00\"), 'temperature': calc_temp, \"year\": 2018, 'month': 11, 'day':29, \\\n",
    "                  'weekday':3, 'hour': 19}, index=[7986] )\n",
    "temps[-1] = pd.concat([temps[-1].iloc[:7986], line, temps[-1].iloc[7986:]]).reset_index(drop=True)\n",
    "                  \n",
    "                  \n",
    "print(temps[-1].iloc[7985:7987])\n",
    "\n",
    "\n",
    "for i in range(len(temps)):\n",
    "    print(temps[i].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52584, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_combined = pd.concat(temps, axis = 0)\n",
    "temp_combined.reset_index(inplace=True, drop=True)\n",
    "temp_combined.shape # should be 52584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90888, 9)\n",
      "(90888, 8)\n",
      "         date  hour  company       gas  year  month  day  weekday  temperature\n",
      "0  2013-01-01     1        0  2497.129  2013      1    1        1         -8.3\n",
      "1  2013-01-01     2        0  2363.265  2013      1    1        1         -8.5\n",
      "2  2013-01-01     3        0  2258.505  2013      1    1        1         -8.4\n",
      "3  2013-01-01     4        0  2243.969  2013      1    1        1         -8.1\n",
      "4  2013-01-01     5        0  2344.105  2013      1    1        1         -8.2\n",
      "5  2013-01-01     6        0  2390.961  2013      1    1        1         -8.2\n",
      "6  2013-01-01     7        0  2378.457  2013      1    1        1         -8.6\n",
      "7  2013-01-01     8        0  2518.921  2013      1    1        1         -8.3\n",
      "8  2013-01-01     9        0  2706.481  2013      1    1        1         -7.9\n",
      "9  2013-01-01    10        0  2832.057  2013      1    1        1         -7.0\n",
      "10 2013-01-01    11        0  2895.185  2013      1    1        1         -5.5\n",
      "11 2013-01-01    12        0  2689.361  2013      1    1        1         -4.2\n",
      "12 2013-01-01    13        0  2425.537  2013      1    1        1         -4.2\n",
      "13 2013-01-01    14        0  2254.289  2013      1    1        1         -1.9\n",
      "14 2013-01-01    15        0  2153.361  2013      1    1        1         -0.6\n",
      "15 2013-01-01    16        0  2126.969  2013      1    1        1         -0.5\n",
      "16 2013-01-01    17        0  2210.481  2013      1    1        1         -0.6\n",
      "17 2013-01-01    18        0  2546.873  2013      1    1        1         -1.1\n",
      "18 2013-01-01    19        0  2886.097  2013      1    1        1         -1.7\n",
      "19 2013-01-01    20        0  2863.009  2013      1    1        1         -1.6\n",
      "         date  hour  company       gas  year  month  day  weekday\n",
      "0  2013-01-01     1        0  2497.129  2013      1    1        1\n",
      "1  2013-01-01     2        0  2363.265  2013      1    1        1\n",
      "2  2013-01-01     3        0  2258.505  2013      1    1        1\n",
      "3  2013-01-01     4        0  2243.969  2013      1    1        1\n",
      "4  2013-01-01     5        0  2344.105  2013      1    1        1\n",
      "5  2013-01-01     6        0  2390.961  2013      1    1        1\n",
      "6  2013-01-01     7        0  2378.457  2013      1    1        1\n",
      "7  2013-01-01     8        0  2518.921  2013      1    1        1\n",
      "8  2013-01-01     9        0  2706.481  2013      1    1        1\n",
      "9  2013-01-01    10        0  2832.057  2013      1    1        1\n",
      "10 2013-01-01    11        0  2895.185  2013      1    1        1\n",
      "11 2013-01-01    12        0  2689.361  2013      1    1        1\n",
      "12 2013-01-01    13        0  2425.537  2013      1    1        1\n",
      "13 2013-01-01    14        0  2254.289  2013      1    1        1\n",
      "14 2013-01-01    15        0  2153.361  2013      1    1        1\n",
      "15 2013-01-01    16        0  2126.969  2013      1    1        1\n",
      "16 2013-01-01    17        0  2210.481  2013      1    1        1\n",
      "17 2013-01-01    18        0  2546.873  2013      1    1        1\n",
      "18 2013-01-01    19        0  2886.097  2013      1    1        1\n",
      "19 2013-01-01    20        0  2863.009  2013      1    1        1\n"
     ]
    }
   ],
   "source": [
    "join_df = pd.merge(total, temp_combined, how='left', left_on=['year', 'month', 'day', 'weekday', 'hour'], right_on=['year', 'month', 'day', 'weekday', 'hour'])\n",
    "join_df.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(join_df.shape)\n",
    "print(total.shape)\n",
    "\n",
    "\n",
    "print(join_df.iloc[:20])\n",
    "print(total.iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2184, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>-2.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">31</th>\n",
       "      <th>20</th>\n",
       "      <td>12.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2184 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                temperature\n",
       "month day hour             \n",
       "1     1   1       -2.683333\n",
       "          2       -3.116667\n",
       "          3       -3.483333\n",
       "          4       -3.716667\n",
       "          5       -4.050000\n",
       "...                     ...\n",
       "3     31  20      12.883333\n",
       "          21      11.800000\n",
       "          22      11.083333\n",
       "          23      10.450000\n",
       "          24       9.950000\n",
       "\n",
       "[2184 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_temp = join_df[['temperature']].groupby([ join_df['month'], join_df['day'], join_df['hour'] ]).apply(lambda c: c.mean())\n",
    "print(daily_temp.shape)\n",
    "daily_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = ['temperature', 'company', 'month', 'day', 'weekday', 'hour', 'year']\n",
    "features = ['temperature', 'company', 'month', 'day', 'weekday', 'hour']\n",
    "\n",
    "\n",
    "train_x_lst = []\n",
    "train_y_lst   = []\n",
    "\n",
    "val_x_lst = []\n",
    "val_y_lst = []\n",
    "\n",
    "for year in range(2013, 2019):\n",
    "    train = join_df[join_df['year'] != year].reset_index(drop = True)\n",
    "    val   = join_df[join_df['year'] == year].reset_index(drop = True)\n",
    "    \n",
    "    train_x = train[features]\n",
    "    train_y = train['gas']\n",
    "    train_x = train_x.values\n",
    "    train_y = np.expand_dims(train_y.values, axis = 1)\n",
    "    \n",
    "    val_x = val[features]\n",
    "    val_y = val['gas']\n",
    "    val_x = val_x.values\n",
    "    val_y = np.expand_dims(val_y.values, axis = 1)\n",
    "    \n",
    "    train_x_lst.append(train_x)\n",
    "    train_y_lst.append(train_y)\n",
    "    \n",
    "    val_x_lst.append(val_x)\n",
    "    val_y_lst.append(val_y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.3 0.  1.  1.  2.  1. ]\n",
      " [2.6 0.  1.  1.  2.  2. ]\n",
      " [1.7 0.  1.  1.  2.  3. ]\n",
      " [1.4 0.  1.  1.  2.  4. ]\n",
      " [0.9 0.  1.  1.  2.  5. ]]\n",
      "[[1677.257]\n",
      " [1567.057]\n",
      " [1458.089]\n",
      " [1458.449]\n",
      " [1587.713]]\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[3.3 0.  1.  1.  2.  1. ]\n",
      " [2.6 0.  1.  1.  2.  2. ]\n",
      " [1.7 0.  1.  1.  2.  3. ]\n",
      " [1.4 0.  1.  1.  2.  4. ]\n",
      " [0.9 0.  1.  1.  2.  5. ]]\n",
      "[[1677.257]\n",
      " [1567.057]\n",
      " [1458.089]\n",
      " [1458.449]\n",
      " [1587.713]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[-6.2  0.   1.   1.   3.   1. ]\n",
      " [-7.4  0.   1.   1.   3.   2. ]\n",
      " [-8.   0.   1.   1.   3.   3. ]\n",
      " [-8.4  0.   1.   1.   3.   4. ]\n",
      " [-8.8  0.   1.   1.   3.   5. ]]\n",
      "[[2228.705]\n",
      " [2098.593]\n",
      " [1960.353]\n",
      " [1959.521]\n",
      " [2061.841]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[-1.9  0.   1.   1.   4.   1. ]\n",
      " [-2.1  0.   1.   1.   4.   2. ]\n",
      " [-2.2  0.   1.   1.   4.   3. ]\n",
      " [-2.5  0.   1.   1.   4.   4. ]\n",
      " [-2.9  0.   1.   1.   4.   5. ]]\n",
      "[[1677.553]\n",
      " [1570.025]\n",
      " [1468.241]\n",
      " [1446.145]\n",
      " [1555.353]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[ 0.2  0.   1.   1.   6.   1. ]\n",
      " [ 0.   0.   1.   1.   6.   2. ]\n",
      " [-0.3  0.   1.   1.   6.   3. ]\n",
      " [-0.7  0.   1.   1.   6.   4. ]\n",
      " [-1.1  0.   1.   1.   6.   5. ]]\n",
      "[[1637.137]\n",
      " [1528.425]\n",
      " [1425.081]\n",
      " [1422.889]\n",
      " [1519.809]]\n",
      "\n",
      "[[-8.3  0.   1.   1.   1.   1. ]\n",
      " [-8.5  0.   1.   1.   1.   2. ]\n",
      " [-8.4  0.   1.   1.   1.   3. ]\n",
      " [-8.1  0.   1.   1.   1.   4. ]\n",
      " [-8.2  0.   1.   1.   1.   5. ]]\n",
      "[[2497.129]\n",
      " [2363.265]\n",
      " [2258.505]\n",
      " [2243.969]\n",
      " [2344.105]]\n",
      "[[-3.2  0.   1.   1.   0.   1. ]\n",
      " [-3.3  0.   1.   1.   0.   2. ]\n",
      " [-3.7  0.   1.   1.   0.   3. ]\n",
      " [-4.   0.   1.   1.   0.   4. ]\n",
      " [-4.2  0.   1.   1.   0.   5. ]]\n",
      "[[1765.008]\n",
      " [1679.186]\n",
      " [1610.885]\n",
      " [1604.123]\n",
      " [1711.506]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_x, train_y, val_x, val_y in zip(train_x_lst, train_y_lst, val_x_lst, val_y_lst):\n",
    "    print(train_x[:5])\n",
    "    print(train_y[:5])\n",
    "    print(val_x[:5])\n",
    "    print(val_y[:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model():    \n",
    "    input_data  = layers.Input(shape=(6,))\n",
    "    out         = layers.Dense(64, activation=\"relu\")(input_data)\n",
    "    out         = layers.BatchNormalization()(out)\n",
    "    out         = layers.Dense(32, activation=\"relu\")(out)\n",
    "    out         = layers.BatchNormalization()(out)\n",
    "    out         = layers.Dense(16, activation=\"relu\")(out)\n",
    "    out         = layers.BatchNormalization()(out)\n",
    "    output      = layers.Dense(1)(out)\n",
    "\n",
    "    model        = tf.keras.Model(inputs = input_data, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size = 0.2, random_state = 1311, shuffle=True)\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def n_mae(y_true, y_pred):\n",
    "    #y_true = y_scaler.inverse_transform(y_true)\n",
    "    #y_pred = y_scaler.inverse_transform(y_pred)\n",
    "    return K.mean((K.abs(y_true-y_pred))/y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "  5/592 [..............................] - ETA: 7s - loss: 0.9998  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:56:45.996908: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - ETA: 0s - loss: 0.9700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:56:52.834632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 12ms/step - loss: 0.9700 - val_loss: 0.9304\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93037, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_001_Val_0.930.hdf5\n",
      "Epoch 2/80\n",
      "592/592 [==============================] - 7s 13ms/step - loss: 0.8753 - val_loss: 0.8478\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93037 to 0.84785, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_002_Val_0.848.hdf5\n",
      "Epoch 3/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8092 - val_loss: 0.7904\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.84785 to 0.79036, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_003_Val_0.790.hdf5\n",
      "Epoch 4/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7565 - val_loss: 0.7390\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.79036 to 0.73902, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_004_Val_0.739.hdf5\n",
      "Epoch 5/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7094 - val_loss: 0.6908\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73902 to 0.69079, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_005_Val_0.691.hdf5\n",
      "Epoch 6/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6653 - val_loss: 0.6611\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69079 to 0.66108, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_006_Val_0.661.hdf5\n",
      "Epoch 7/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6185 - val_loss: 0.5959\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.66108 to 0.59588, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_007_Val_0.596.hdf5\n",
      "Epoch 8/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5717 - val_loss: 0.5522\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59588 to 0.55224, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_008_Val_0.552.hdf5\n",
      "Epoch 9/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5250 - val_loss: 0.5203\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55224 to 0.52032, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_009_Val_0.520.hdf5\n",
      "Epoch 10/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4789 - val_loss: 0.4747\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52032 to 0.47473, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_010_Val_0.475.hdf5\n",
      "Epoch 11/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4381 - val_loss: 0.4309\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.47473 to 0.43087, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_011_Val_0.431.hdf5\n",
      "Epoch 12/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3990 - val_loss: 0.3834\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43087 to 0.38336, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_012_Val_0.383.hdf5\n",
      "Epoch 13/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3648 - val_loss: 0.3907\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.38336\n",
      "Epoch 14/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3339 - val_loss: 0.3395\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.38336 to 0.33948, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_014_Val_0.339.hdf5\n",
      "Epoch 15/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3054 - val_loss: 0.2825\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33948 to 0.28252, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_015_Val_0.283.hdf5\n",
      "Epoch 16/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2809 - val_loss: 0.2610\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.28252 to 0.26105, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_016_Val_0.261.hdf5\n",
      "Epoch 17/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2570 - val_loss: 0.2464\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26105 to 0.24635, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_017_Val_0.246.hdf5\n",
      "Epoch 18/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2421 - val_loss: 0.2061\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24635 to 0.20614, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_018_Val_0.206.hdf5\n",
      "Epoch 19/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2247 - val_loss: 0.2016\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20614 to 0.20162, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_019_Val_0.202.hdf5\n",
      "Epoch 20/80\n",
      "592/592 [==============================] - 5s 9ms/step - loss: 0.2067 - val_loss: 0.2043\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20162\n",
      "Epoch 21/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2003 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.20162 to 0.16774, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_021_Val_0.168.hdf5\n",
      "Epoch 22/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1910 - val_loss: 0.1724\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16774\n",
      "Epoch 23/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1836 - val_loss: 0.1573\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16774 to 0.15726, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_023_Val_0.157.hdf5\n",
      "Epoch 24/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1723 - val_loss: 0.1807\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15726\n",
      "Epoch 25/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1694 - val_loss: 0.1338\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.15726 to 0.13379, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_025_Val_0.134.hdf5\n",
      "Epoch 26/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1658 - val_loss: 0.1351\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.13379\n",
      "Epoch 27/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1546 - val_loss: 0.1469\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13379\n",
      "Epoch 28/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1523 - val_loss: 0.1547\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13379\n",
      "Epoch 29/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1485 - val_loss: 0.1224\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13379 to 0.12245, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_029_Val_0.122.hdf5\n",
      "Epoch 30/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1436 - val_loss: 0.1379\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.12245\n",
      "Epoch 31/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1433 - val_loss: 0.1473\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.12245\n",
      "Epoch 32/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1392 - val_loss: 0.1080\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12245 to 0.10803, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_032_Val_0.108.hdf5\n",
      "Epoch 33/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1368 - val_loss: 0.1525\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10803\n",
      "Epoch 34/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1324 - val_loss: 0.1478\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10803\n",
      "Epoch 35/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1313 - val_loss: 0.1222\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10803\n",
      "Epoch 36/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1339 - val_loss: 0.0989\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.10803 to 0.09888, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_036_Val_0.099.hdf5\n",
      "Epoch 37/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1261 - val_loss: 0.1107\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.09888\n",
      "Epoch 38/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1228 - val_loss: 0.1135\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.09888\n",
      "Epoch 39/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1207 - val_loss: 0.1350\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.09888\n",
      "Epoch 40/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1197 - val_loss: 0.1294\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.09888\n",
      "Epoch 41/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1218 - val_loss: 0.1155\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.09888\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1180 - val_loss: 0.2247\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.09888\n",
      "Epoch 43/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1145 - val_loss: 0.1079\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.09888\n",
      "Epoch 44/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1116 - val_loss: 0.0958\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.09888 to 0.09581, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_044_Val_0.096.hdf5\n",
      "Epoch 45/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1109 - val_loss: 0.1039\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.09581\n",
      "Epoch 46/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1109 - val_loss: 0.1473\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.09581\n",
      "Epoch 47/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1093 - val_loss: 0.0990\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.09581\n",
      "Epoch 48/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1085 - val_loss: 0.0943\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.09581 to 0.09429, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_048_Val_0.094.hdf5\n",
      "Epoch 49/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1075 - val_loss: 0.1120\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.09429\n",
      "Epoch 50/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1084 - val_loss: 0.1204\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.09429\n",
      "Epoch 51/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1045 - val_loss: 0.1244\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.09429\n",
      "Epoch 52/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1048 - val_loss: 0.1009\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.09429\n",
      "Epoch 53/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1030 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.09429 to 0.09145, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_053_Val_0.091.hdf5\n",
      "Epoch 54/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1063 - val_loss: 0.0972\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.09145\n",
      "Epoch 55/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1043 - val_loss: 0.0981\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.09145\n",
      "Epoch 56/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1023 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.09145 to 0.08563, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_056_Val_0.086.hdf5\n",
      "Epoch 57/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1026 - val_loss: 0.1026\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.08563\n",
      "Epoch 58/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1021 - val_loss: 0.0918\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.08563\n",
      "Epoch 59/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1010 - val_loss: 0.0928\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.08563\n",
      "Epoch 60/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1016 - val_loss: 0.0775\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08563 to 0.07747, saving model to ./Models/DNN_temp/valid_year_2013/Epoch_060_Val_0.077.hdf5\n",
      "Epoch 61/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1020 - val_loss: 0.1027\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07747\n",
      "Epoch 62/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0969 - val_loss: 0.1154\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07747\n",
      "Epoch 63/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0981 - val_loss: 0.0928\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07747\n",
      "Epoch 64/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0994 - val_loss: 0.0816\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.07747\n",
      "Epoch 65/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0982 - val_loss: 0.1207\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07747\n",
      "Epoch 66/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0993 - val_loss: 0.1191\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.07747\n",
      "Epoch 67/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0988 - val_loss: 0.0807\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.07747\n",
      "Epoch 68/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0963 - val_loss: 0.0985\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.07747\n",
      "Epoch 69/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0974 - val_loss: 0.1046\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07747\n",
      "Epoch 70/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0952 - val_loss: 0.0996\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07747\n",
      "Epoch 71/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0946 - val_loss: 0.0910\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.07747\n",
      "Epoch 72/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0954 - val_loss: 0.0815\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.07747\n",
      "Epoch 73/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0957 - val_loss: 0.1314\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07747\n",
      "Epoch 74/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0954 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.07747\n",
      "Epoch 75/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0947 - val_loss: 0.0864\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.07747\n",
      "Epoch 76/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0945 - val_loss: 0.0973\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07747\n",
      "Epoch 77/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0953 - val_loss: 0.1130\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07747\n",
      "Epoch 78/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0966 - val_loss: 0.0854\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07747\n",
      "Epoch 79/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0930 - val_loss: 0.0864\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07747\n",
      "Epoch 80/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0928 - val_loss: 0.0913\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07747\n",
      "Epoch 00080: early stopping\n",
      "Epoch 1/80\n",
      "  6/592 [..............................] - ETA: 6s - loss: 0.9998  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:05:47.946942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:05:54.507807: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.9690 - val_loss: 0.9321\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93212, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_001_Val_0.932.hdf5\n",
      "Epoch 2/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8771 - val_loss: 0.8390\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93212 to 0.83897, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_002_Val_0.839.hdf5\n",
      "Epoch 3/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.8258 - val_loss: 0.7987\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.83897 to 0.79874, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_003_Val_0.799.hdf5\n",
      "Epoch 4/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7831 - val_loss: 0.7553\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.79874 to 0.75530, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_004_Val_0.755.hdf5\n",
      "Epoch 5/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7323 - val_loss: 0.6841\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75530 to 0.68414, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_005_Val_0.684.hdf5\n",
      "Epoch 6/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6739 - val_loss: 0.6269\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68414 to 0.62694, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_006_Val_0.627.hdf5\n",
      "Epoch 7/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6188 - val_loss: 0.5563\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62694 to 0.55625, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_007_Val_0.556.hdf5\n",
      "Epoch 8/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5708 - val_loss: 0.5091\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55625 to 0.50906, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_008_Val_0.509.hdf5\n",
      "Epoch 9/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5239 - val_loss: 0.4543\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50906 to 0.45432, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_009_Val_0.454.hdf5\n",
      "Epoch 10/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4820 - val_loss: 0.4298\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45432 to 0.42978, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_010_Val_0.430.hdf5\n",
      "Epoch 11/80\n",
      "592/592 [==============================] - 7s 13ms/step - loss: 0.4440 - val_loss: 0.3948\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.42978 to 0.39483, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_011_Val_0.395.hdf5\n",
      "Epoch 12/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4104 - val_loss: 0.3390\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.39483 to 0.33902, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_012_Val_0.339.hdf5\n",
      "Epoch 13/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3783 - val_loss: 0.3314\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33902 to 0.33138, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_013_Val_0.331.hdf5\n",
      "Epoch 14/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3503 - val_loss: 0.2913\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33138 to 0.29129, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_014_Val_0.291.hdf5\n",
      "Epoch 15/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3214 - val_loss: 0.2652\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.29129 to 0.26516, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_015_Val_0.265.hdf5\n",
      "Epoch 16/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2983 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.26516 to 0.22896, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_016_Val_0.229.hdf5\n",
      "Epoch 17/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2754 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22896 to 0.21451, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_017_Val_0.215.hdf5\n",
      "Epoch 18/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2552 - val_loss: 0.2048\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.21451 to 0.20476, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_018_Val_0.205.hdf5\n",
      "Epoch 19/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2381 - val_loss: 0.2050\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20476\n",
      "Epoch 20/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2251 - val_loss: 0.1780\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20476 to 0.17801, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_020_Val_0.178.hdf5\n",
      "Epoch 21/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2125 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.17801 to 0.16705, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_021_Val_0.167.hdf5\n",
      "Epoch 22/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1977 - val_loss: 0.1465\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16705 to 0.14645, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_022_Val_0.146.hdf5\n",
      "Epoch 23/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1891 - val_loss: 0.1616\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14645\n",
      "Epoch 24/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1804 - val_loss: 0.1230\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14645 to 0.12297, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_024_Val_0.123.hdf5\n",
      "Epoch 25/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1686 - val_loss: 0.1282\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12297\n",
      "Epoch 26/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1567 - val_loss: 0.1254\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.12297\n",
      "Epoch 27/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1481 - val_loss: 0.1395\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.12297\n",
      "Epoch 28/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1444 - val_loss: 0.1079\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.12297 to 0.10785, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_028_Val_0.108.hdf5\n",
      "Epoch 29/80\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.1394 - val_loss: 0.1120\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10785\n",
      "Epoch 30/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1351 - val_loss: 0.1363\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10785\n",
      "Epoch 31/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1320 - val_loss: 0.0932\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.10785 to 0.09323, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_031_Val_0.093.hdf5\n",
      "Epoch 32/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1296 - val_loss: 0.0959\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.09323\n",
      "Epoch 33/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1252 - val_loss: 0.0978\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.09323\n",
      "Epoch 34/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1246 - val_loss: 0.1221\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.09323\n",
      "Epoch 35/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1216 - val_loss: 0.1139\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.09323\n",
      "Epoch 36/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1207 - val_loss: 0.0922\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.09323 to 0.09219, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_036_Val_0.092.hdf5\n",
      "Epoch 37/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1183 - val_loss: 0.1038\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.09219\n",
      "Epoch 38/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1186 - val_loss: 0.1326\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.09219\n",
      "Epoch 39/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1181 - val_loss: 0.0977\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.09219\n",
      "Epoch 40/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1147 - val_loss: 0.0977\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.09219\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1155 - val_loss: 0.0983\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.09219\n",
      "Epoch 42/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1134 - val_loss: 0.0805\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.09219 to 0.08048, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_042_Val_0.080.hdf5\n",
      "Epoch 43/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1092 - val_loss: 0.0803\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08048 to 0.08028, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_043_Val_0.080.hdf5\n",
      "Epoch 44/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1125 - val_loss: 0.1003\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08028\n",
      "Epoch 45/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1092 - val_loss: 0.0780\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08028 to 0.07798, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_045_Val_0.078.hdf5\n",
      "Epoch 46/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1068 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07798\n",
      "Epoch 47/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1096 - val_loss: 0.0919\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07798\n",
      "Epoch 48/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1064 - val_loss: 0.0778\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07798 to 0.07779, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_048_Val_0.078.hdf5\n",
      "Epoch 49/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1079 - val_loss: 0.0881\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07779\n",
      "Epoch 50/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1049 - val_loss: 0.0920\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07779\n",
      "Epoch 51/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1078 - val_loss: 0.0948\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.07779\n",
      "Epoch 52/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1066 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.07779\n",
      "Epoch 53/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1023 - val_loss: 0.0787\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07779\n",
      "Epoch 54/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1025 - val_loss: 0.0862\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.07779\n",
      "Epoch 55/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1022 - val_loss: 0.0846\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.07779\n",
      "Epoch 56/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1017 - val_loss: 0.0840\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.07779\n",
      "Epoch 57/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1000 - val_loss: 0.0788\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.07779\n",
      "Epoch 58/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1030 - val_loss: 0.0875\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.07779\n",
      "Epoch 59/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1032 - val_loss: 0.0827\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.07779\n",
      "Epoch 60/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0993 - val_loss: 0.0752\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07779 to 0.07521, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_060_Val_0.075.hdf5\n",
      "Epoch 61/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1025 - val_loss: 0.0823\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07521\n",
      "Epoch 62/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0978 - val_loss: 0.0770\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07521\n",
      "Epoch 63/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0996 - val_loss: 0.0784\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07521\n",
      "Epoch 64/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1050 - val_loss: 0.0889\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.07521\n",
      "Epoch 65/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0994 - val_loss: 0.0765\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07521\n",
      "Epoch 66/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0975 - val_loss: 0.0756\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.07521\n",
      "Epoch 67/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0974 - val_loss: 0.0922\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.07521\n",
      "Epoch 68/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0969 - val_loss: 0.0821\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.07521\n",
      "Epoch 69/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0971 - val_loss: 0.0742\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.07521 to 0.07420, saving model to ./Models/DNN_temp/valid_year_2014/Epoch_069_Val_0.074.hdf5\n",
      "Epoch 70/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0962 - val_loss: 0.0950\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07420\n",
      "Epoch 71/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0960 - val_loss: 0.0802\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.07420\n",
      "Epoch 72/80\n",
      "592/592 [==============================] - 8s 14ms/step - loss: 0.0977 - val_loss: 0.0743\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.07420\n",
      "Epoch 73/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0951 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07420\n",
      "Epoch 74/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0971 - val_loss: 0.0808\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.07420\n",
      "Epoch 75/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0950 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.07420\n",
      "Epoch 76/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0939 - val_loss: 0.0748\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07420\n",
      "Epoch 77/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0963 - val_loss: 0.0819\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07420\n",
      "Epoch 78/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0957 - val_loss: 0.0858\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07420\n",
      "Epoch 79/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0947 - val_loss: 0.0798\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07420\n",
      "Epoch 80/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0933 - val_loss: 0.0760\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07420\n",
      "Epoch 1/80\n",
      "  6/592 [..............................] - ETA: 6s - loss: 1.0000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:15:00.698066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:15:07.169079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.9794 - val_loss: 0.9958\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99581, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_001_Val_0.996.hdf5\n",
      "Epoch 2/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8633 - val_loss: 0.8100\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.99581 to 0.80997, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_002_Val_0.810.hdf5\n",
      "Epoch 3/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.8031 - val_loss: 0.7778\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80997 to 0.77781, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_003_Val_0.778.hdf5\n",
      "Epoch 4/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7604 - val_loss: 0.7330\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.77781 to 0.73297, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_004_Val_0.733.hdf5\n",
      "Epoch 5/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7078 - val_loss: 0.6723\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73297 to 0.67228, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_005_Val_0.672.hdf5\n",
      "Epoch 6/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6590 - val_loss: 0.6221\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67228 to 0.62213, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_006_Val_0.622.hdf5\n",
      "Epoch 7/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6169 - val_loss: 0.5745\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62213 to 0.57455, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_007_Val_0.575.hdf5\n",
      "Epoch 8/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5793 - val_loss: 0.5429\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.57455 to 0.54289, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_008_Val_0.543.hdf5\n",
      "Epoch 9/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5464 - val_loss: 0.5009\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.54289 to 0.50086, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_009_Val_0.501.hdf5\n",
      "Epoch 10/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5160 - val_loss: 0.4670\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.50086 to 0.46695, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_010_Val_0.467.hdf5\n",
      "Epoch 11/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4881 - val_loss: 0.4652\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.46695 to 0.46525, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_011_Val_0.465.hdf5\n",
      "Epoch 12/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4618 - val_loss: 0.4305\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.46525 to 0.43046, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_012_Val_0.430.hdf5\n",
      "Epoch 13/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4360 - val_loss: 0.4011\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43046 to 0.40106, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_013_Val_0.401.hdf5\n",
      "Epoch 14/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4139 - val_loss: 0.3709\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40106 to 0.37087, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_014_Val_0.371.hdf5\n",
      "Epoch 15/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3933 - val_loss: 0.3569\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.37087 to 0.35686, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_015_Val_0.357.hdf5\n",
      "Epoch 16/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3748 - val_loss: 0.3411\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.35686 to 0.34110, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_016_Val_0.341.hdf5\n",
      "Epoch 17/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3552 - val_loss: 0.3144\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34110 to 0.31442, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_017_Val_0.314.hdf5\n",
      "Epoch 18/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3385 - val_loss: 0.3217\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31442\n",
      "Epoch 19/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3217 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.31442 to 0.28974, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_019_Val_0.290.hdf5\n",
      "Epoch 20/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2923 - val_loss: 0.2664\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.28974 to 0.26639, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_020_Val_0.266.hdf5\n",
      "Epoch 21/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2715 - val_loss: 0.2496\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.26639 to 0.24963, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_021_Val_0.250.hdf5\n",
      "Epoch 22/80\n",
      "592/592 [==============================] - 8s 14ms/step - loss: 0.2532 - val_loss: 0.2434\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.24963 to 0.24341, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_022_Val_0.243.hdf5\n",
      "Epoch 23/80\n",
      "592/592 [==============================] - 641s 1s/step - loss: 0.2378 - val_loss: 0.1959\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24341 to 0.19587, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_023_Val_0.196.hdf5\n",
      "Epoch 24/80\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.2181 - val_loss: 0.2071\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19587\n",
      "Epoch 25/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1973 - val_loss: 0.1897\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19587 to 0.18969, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_025_Val_0.190.hdf5\n",
      "Epoch 26/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1825 - val_loss: 0.1457\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.18969 to 0.14572, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_026_Val_0.146.hdf5\n",
      "Epoch 27/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1711 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14572\n",
      "Epoch 28/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1564 - val_loss: 0.1184\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.14572 to 0.11841, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_028_Val_0.118.hdf5\n",
      "Epoch 29/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1481 - val_loss: 0.1352\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11841\n",
      "Epoch 30/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1405 - val_loss: 0.1134\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.11841 to 0.11337, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_030_Val_0.113.hdf5\n",
      "Epoch 31/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1350 - val_loss: 0.1081\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.11337 to 0.10813, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_031_Val_0.108.hdf5\n",
      "Epoch 32/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1319 - val_loss: 0.1151\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10813\n",
      "Epoch 33/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1277 - val_loss: 0.0971\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.10813 to 0.09713, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_033_Val_0.097.hdf5\n",
      "Epoch 34/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1257 - val_loss: 0.1075\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.09713\n",
      "Epoch 35/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1221 - val_loss: 0.1086\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.09713\n",
      "Epoch 36/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1201 - val_loss: 0.0916\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.09713 to 0.09163, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_036_Val_0.092.hdf5\n",
      "Epoch 37/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1193 - val_loss: 0.0960\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.09163\n",
      "Epoch 38/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1186 - val_loss: 0.1004\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.09163\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1145 - val_loss: 0.1031\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.09163\n",
      "Epoch 40/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1150 - val_loss: 0.0959\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.09163\n",
      "Epoch 41/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1114 - val_loss: 0.0962\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.09163\n",
      "Epoch 42/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1126 - val_loss: 0.0903\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.09163 to 0.09031, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_042_Val_0.090.hdf5\n",
      "Epoch 43/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1090 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.09031 to 0.08626, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_043_Val_0.086.hdf5\n",
      "Epoch 44/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1082 - val_loss: 0.0908\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08626\n",
      "Epoch 45/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1079 - val_loss: 0.0963\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08626\n",
      "Epoch 46/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1057 - val_loss: 0.0871\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08626\n",
      "Epoch 47/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1042 - val_loss: 0.0863\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08626 to 0.08626, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_047_Val_0.086.hdf5\n",
      "Epoch 48/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1044 - val_loss: 0.0980\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08626\n",
      "Epoch 49/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1033 - val_loss: 0.0805\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.08626 to 0.08047, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_049_Val_0.080.hdf5\n",
      "Epoch 50/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1024 - val_loss: 0.0785\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08047 to 0.07852, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_050_Val_0.079.hdf5\n",
      "Epoch 51/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1022 - val_loss: 0.0809\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.07852\n",
      "Epoch 52/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1018 - val_loss: 0.0816\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.07852\n",
      "Epoch 53/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1023 - val_loss: 0.0800\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07852\n",
      "Epoch 54/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1010 - val_loss: 0.1222\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.07852\n",
      "Epoch 55/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1018 - val_loss: 0.0786\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.07852\n",
      "Epoch 56/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1004 - val_loss: 0.0822\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.07852\n",
      "Epoch 57/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0992 - val_loss: 0.0779\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.07852 to 0.07787, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_057_Val_0.078.hdf5\n",
      "Epoch 58/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0979 - val_loss: 0.0683\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.07787 to 0.06832, saving model to ./Models/DNN_temp/valid_year_2015/Epoch_058_Val_0.068.hdf5\n",
      "Epoch 59/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0990 - val_loss: 0.0754\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.06832\n",
      "Epoch 60/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0982 - val_loss: 0.0745\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.06832\n",
      "Epoch 61/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0975 - val_loss: 0.0736\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06832\n",
      "Epoch 62/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0952 - val_loss: 0.0804\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06832\n",
      "Epoch 63/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0977 - val_loss: 0.0819\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06832\n",
      "Epoch 64/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0948 - val_loss: 0.0731\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06832\n",
      "Epoch 65/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0972 - val_loss: 0.0734\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.06832\n",
      "Epoch 66/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0935 - val_loss: 0.0752\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.06832\n",
      "Epoch 67/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0956 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06832\n",
      "Epoch 68/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0943 - val_loss: 0.0755\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06832\n",
      "Epoch 69/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0954 - val_loss: 0.0766\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06832\n",
      "Epoch 70/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0938 - val_loss: 0.0794\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06832\n",
      "Epoch 71/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0934 - val_loss: 0.0761\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06832\n",
      "Epoch 72/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0941 - val_loss: 0.0698\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06832\n",
      "Epoch 73/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0951 - val_loss: 0.0765\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06832\n",
      "Epoch 74/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0936 - val_loss: 0.0759\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06832\n",
      "Epoch 75/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0920 - val_loss: 0.0772\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06832\n",
      "Epoch 76/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0933 - val_loss: 0.0690\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06832\n",
      "Epoch 77/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0933 - val_loss: 0.0789\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06832\n",
      "Epoch 78/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0932 - val_loss: 0.0684\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06832\n",
      "Epoch 00078: early stopping\n",
      "Epoch 1/80\n",
      "  6/591 [..............................] - ETA: 6s - loss: 0.9999  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:34:24.212859: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - ETA: 0s - loss: 0.9719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:34:30.752426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 7s 11ms/step - loss: 0.9719 - val_loss: 0.9595\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.95947, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_001_Val_0.959.hdf5\n",
      "Epoch 2/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.8606 - val_loss: 0.8128\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.95947 to 0.81275, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_002_Val_0.813.hdf5\n",
      "Epoch 3/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.7824 - val_loss: 0.7741\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81275 to 0.77406, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_003_Val_0.774.hdf5\n",
      "Epoch 4/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.7334 - val_loss: 0.7188\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.77406 to 0.71884, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_004_Val_0.719.hdf5\n",
      "Epoch 5/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.7013 - val_loss: 0.6935\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71884 to 0.69352, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_005_Val_0.694.hdf5\n",
      "Epoch 6/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.6697 - val_loss: 0.6625\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69352 to 0.66251, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_006_Val_0.663.hdf5\n",
      "Epoch 7/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.6273 - val_loss: 0.6137\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.66251 to 0.61375, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_007_Val_0.614.hdf5\n",
      "Epoch 8/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.5826 - val_loss: 0.5611\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.61375 to 0.56113, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_008_Val_0.561.hdf5\n",
      "Epoch 9/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.5398 - val_loss: 0.5113\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56113 to 0.51133, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_009_Val_0.511.hdf5\n",
      "Epoch 10/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.5009 - val_loss: 0.4800\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.51133 to 0.48004, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_010_Val_0.480.hdf5\n",
      "Epoch 11/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.4671 - val_loss: 0.4491\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.48004 to 0.44907, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_011_Val_0.449.hdf5\n",
      "Epoch 12/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.4355 - val_loss: 0.4140\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44907 to 0.41401, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_012_Val_0.414.hdf5\n",
      "Epoch 13/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.4064 - val_loss: 0.3837\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.41401 to 0.38370, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_013_Val_0.384.hdf5\n",
      "Epoch 14/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.3777 - val_loss: 0.3696\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.38370 to 0.36960, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_014_Val_0.370.hdf5\n",
      "Epoch 15/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.3544 - val_loss: 0.3314\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.36960 to 0.33135, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_015_Val_0.331.hdf5\n",
      "Epoch 16/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.3307 - val_loss: 0.3131\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33135 to 0.31311, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_016_Val_0.313.hdf5\n",
      "Epoch 17/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.3095 - val_loss: 0.2877\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.31311 to 0.28773, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_017_Val_0.288.hdf5\n",
      "Epoch 18/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2914 - val_loss: 0.2798\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.28773 to 0.27981, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_018_Val_0.280.hdf5\n",
      "Epoch 19/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2754 - val_loss: 0.2461\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.27981 to 0.24610, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_019_Val_0.246.hdf5\n",
      "Epoch 20/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2590 - val_loss: 0.2631\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24610\n",
      "Epoch 21/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2432 - val_loss: 0.2139\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.24610 to 0.21394, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_021_Val_0.214.hdf5\n",
      "Epoch 22/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2287 - val_loss: 0.1993\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21394 to 0.19930, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_022_Val_0.199.hdf5\n",
      "Epoch 23/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2163 - val_loss: 0.1975\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.19930 to 0.19746, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_023_Val_0.197.hdf5\n",
      "Epoch 24/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.2045 - val_loss: 0.2163\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19746\n",
      "Epoch 25/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1958 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19746 to 0.17043, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_025_Val_0.170.hdf5\n",
      "Epoch 26/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1828 - val_loss: 0.1529\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17043 to 0.15290, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_026_Val_0.153.hdf5\n",
      "Epoch 27/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1738 - val_loss: 0.1510\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.15290 to 0.15097, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_027_Val_0.151.hdf5\n",
      "Epoch 28/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1641 - val_loss: 0.1506\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.15097 to 0.15056, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_028_Val_0.151.hdf5\n",
      "Epoch 29/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1569 - val_loss: 0.1359\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15056 to 0.13587, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_029_Val_0.136.hdf5\n",
      "Epoch 30/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1468 - val_loss: 0.1313\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.13587 to 0.13128, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_030_Val_0.131.hdf5\n",
      "Epoch 31/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1404 - val_loss: 0.1209\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.13128 to 0.12090, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_031_Val_0.121.hdf5\n",
      "Epoch 32/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1310 - val_loss: 0.1238\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.12090\n",
      "Epoch 33/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1267 - val_loss: 0.1205\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12090 to 0.12053, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_033_Val_0.121.hdf5\n",
      "Epoch 34/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1239 - val_loss: 0.1133\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.12053 to 0.11328, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_034_Val_0.113.hdf5\n",
      "Epoch 35/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1229 - val_loss: 0.1165\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11328\n",
      "Epoch 36/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1216 - val_loss: 0.1206\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11328\n",
      "Epoch 37/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1174 - val_loss: 0.1002\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11328 to 0.10018, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_037_Val_0.100.hdf5\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1161 - val_loss: 0.1176\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10018\n",
      "Epoch 39/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1128 - val_loss: 0.1040\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.10018\n",
      "Epoch 40/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1149 - val_loss: 0.1006\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10018\n",
      "Epoch 41/80\n",
      "591/591 [==============================] - 7s 11ms/step - loss: 0.1112 - val_loss: 0.1146\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10018\n",
      "Epoch 42/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1126 - val_loss: 0.1000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10018 to 0.10005, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_042_Val_0.100.hdf5\n",
      "Epoch 43/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1111 - val_loss: 0.1124\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.10005\n",
      "Epoch 44/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1102 - val_loss: 0.1113\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.10005\n",
      "Epoch 45/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1093 - val_loss: 0.1123\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10005\n",
      "Epoch 46/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1085 - val_loss: 0.1125\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10005\n",
      "Epoch 47/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1080 - val_loss: 0.1042\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10005\n",
      "Epoch 48/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1064 - val_loss: 0.1042\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10005\n",
      "Epoch 49/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1067 - val_loss: 0.1022\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10005\n",
      "Epoch 50/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1044 - val_loss: 0.0947\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.10005 to 0.09470, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_050_Val_0.095.hdf5\n",
      "Epoch 51/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1067 - val_loss: 0.1047\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.09470\n",
      "Epoch 52/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1040 - val_loss: 0.0984\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.09470\n",
      "Epoch 53/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1055 - val_loss: 0.1057\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.09470\n",
      "Epoch 54/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1039 - val_loss: 0.1046\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.09470\n",
      "Epoch 55/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1052 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.09470\n",
      "Epoch 56/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1021 - val_loss: 0.1013\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.09470\n",
      "Epoch 57/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1018 - val_loss: 0.1102\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.09470\n",
      "Epoch 58/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1022 - val_loss: 0.1285\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.09470\n",
      "Epoch 59/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.1012 - val_loss: 0.1027\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.09470\n",
      "Epoch 60/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0991 - val_loss: 0.1044\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.09470\n",
      "Epoch 61/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0990 - val_loss: 0.0945\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.09470 to 0.09449, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_061_Val_0.094.hdf5\n",
      "Epoch 62/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0975 - val_loss: 0.1003\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.09449\n",
      "Epoch 63/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0973 - val_loss: 0.1022\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.09449\n",
      "Epoch 64/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0976 - val_loss: 0.1128\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.09449\n",
      "Epoch 65/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0953 - val_loss: 0.1008\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.09449\n",
      "Epoch 66/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0943 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.09449 to 0.09285, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_066_Val_0.093.hdf5\n",
      "Epoch 67/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0945 - val_loss: 0.0845\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09285 to 0.08450, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_067_Val_0.085.hdf5\n",
      "Epoch 68/80\n",
      "591/591 [==============================] - 6s 11ms/step - loss: 0.0948 - val_loss: 0.1013\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08450\n",
      "Epoch 69/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0944 - val_loss: 0.0923\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08450\n",
      "Epoch 70/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0932 - val_loss: 0.0856\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08450\n",
      "Epoch 71/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0938 - val_loss: 0.0944\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08450\n",
      "Epoch 72/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0948 - val_loss: 0.0893\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08450\n",
      "Epoch 73/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0909 - val_loss: 0.0985\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08450\n",
      "Epoch 74/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0907 - val_loss: 0.0887\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08450\n",
      "Epoch 75/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0929 - val_loss: 0.0911\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08450\n",
      "Epoch 76/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0907 - val_loss: 0.0896\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.08450\n",
      "Epoch 77/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0922 - val_loss: 0.0866\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08450\n",
      "Epoch 78/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0922 - val_loss: 0.0825\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.08450 to 0.08253, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_078_Val_0.083.hdf5\n",
      "Epoch 79/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0920 - val_loss: 0.0817\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.08253 to 0.08172, saving model to ./Models/DNN_temp/valid_year_2016/Epoch_079_Val_0.082.hdf5\n",
      "Epoch 80/80\n",
      "591/591 [==============================] - 7s 12ms/step - loss: 0.0919 - val_loss: 0.0869\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08172\n",
      "Epoch 1/80\n",
      "  6/592 [..............................] - ETA: 6s - loss: 1.0001  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:43:13.774502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:43:20.314565: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.9721 - val_loss: 0.9540\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.95396, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_001_Val_0.954.hdf5\n",
      "Epoch 2/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8671 - val_loss: 0.8280\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.95396 to 0.82797, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_002_Val_0.828.hdf5\n",
      "Epoch 3/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7956 - val_loss: 0.7684\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.82797 to 0.76843, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_003_Val_0.768.hdf5\n",
      "Epoch 4/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.7448 - val_loss: 0.7350\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.76843 to 0.73498, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_004_Val_0.735.hdf5\n",
      "Epoch 5/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7026 - val_loss: 0.6858\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73498 to 0.68583, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_005_Val_0.686.hdf5\n",
      "Epoch 6/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6602 - val_loss: 0.6218\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68583 to 0.62184, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_006_Val_0.622.hdf5\n",
      "Epoch 7/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6152 - val_loss: 0.5903\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62184 to 0.59033, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_007_Val_0.590.hdf5\n",
      "Epoch 8/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5699 - val_loss: 0.5154\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59033 to 0.51538, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_008_Val_0.515.hdf5\n",
      "Epoch 9/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5279 - val_loss: 0.5300\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.51538\n",
      "Epoch 10/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4854 - val_loss: 0.4441\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.51538 to 0.44411, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_010_Val_0.444.hdf5\n",
      "Epoch 11/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4444 - val_loss: 0.4176\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.44411 to 0.41760, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_011_Val_0.418.hdf5\n",
      "Epoch 12/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4079 - val_loss: 0.3615\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.41760 to 0.36146, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_012_Val_0.361.hdf5\n",
      "Epoch 13/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3757 - val_loss: 0.3569\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36146 to 0.35688, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_013_Val_0.357.hdf5\n",
      "Epoch 14/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3446 - val_loss: 0.3155\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35688 to 0.31546, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_014_Val_0.315.hdf5\n",
      "Epoch 15/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.3172 - val_loss: 0.2745\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31546 to 0.27450, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_015_Val_0.274.hdf5\n",
      "Epoch 16/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2926 - val_loss: 0.2559\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27450 to 0.25591, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_016_Val_0.256.hdf5\n",
      "Epoch 17/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2697 - val_loss: 0.2277\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25591 to 0.22767, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_017_Val_0.228.hdf5\n",
      "Epoch 18/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2531 - val_loss: 0.2031\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.22767 to 0.20308, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_018_Val_0.203.hdf5\n",
      "Epoch 19/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2352 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20308 to 0.17398, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_019_Val_0.174.hdf5\n",
      "Epoch 20/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2248 - val_loss: 0.1725\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.17398 to 0.17248, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_020_Val_0.172.hdf5\n",
      "Epoch 21/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2151 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.17248\n",
      "Epoch 22/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2014 - val_loss: 0.1837\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17248\n",
      "Epoch 23/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1970 - val_loss: 0.1409\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.17248 to 0.14091, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_023_Val_0.141.hdf5\n",
      "Epoch 24/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1868 - val_loss: 0.1294\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14091 to 0.12945, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_024_Val_0.129.hdf5\n",
      "Epoch 25/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1840 - val_loss: 0.1249\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.12945 to 0.12491, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_025_Val_0.125.hdf5\n",
      "Epoch 26/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1689 - val_loss: 0.1169\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12491 to 0.11687, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_026_Val_0.117.hdf5\n",
      "Epoch 27/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1657 - val_loss: 0.1074\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11687 to 0.10740, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_027_Val_0.107.hdf5\n",
      "Epoch 28/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1667 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10740\n",
      "Epoch 29/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1630 - val_loss: 0.1139\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10740\n",
      "Epoch 30/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1588 - val_loss: 0.0965\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.10740 to 0.09649, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_030_Val_0.096.hdf5\n",
      "Epoch 31/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1532 - val_loss: 0.0917\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.09649 to 0.09166, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_031_Val_0.092.hdf5\n",
      "Epoch 32/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1536 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.09166 to 0.09150, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_032_Val_0.091.hdf5\n",
      "Epoch 33/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1446 - val_loss: 0.1259\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.09150\n",
      "Epoch 34/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1440 - val_loss: 0.0818\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.09150 to 0.08184, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_034_Val_0.082.hdf5\n",
      "Epoch 35/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1392 - val_loss: 0.0954\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08184\n",
      "Epoch 36/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1398 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08184\n",
      "Epoch 37/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1315 - val_loss: 0.1210\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08184\n",
      "Epoch 38/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1301 - val_loss: 0.0961\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08184\n",
      "Epoch 39/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1269 - val_loss: 0.0940\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08184\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1235 - val_loss: 0.1076\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08184\n",
      "Epoch 41/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1226 - val_loss: 0.0859\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08184\n",
      "Epoch 42/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1190 - val_loss: 0.0995\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08184\n",
      "Epoch 43/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1198 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08184\n",
      "Epoch 44/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1143 - val_loss: 0.0786\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08184 to 0.07859, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_044_Val_0.079.hdf5\n",
      "Epoch 45/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1143 - val_loss: 0.0732\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.07859 to 0.07317, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_045_Val_0.073.hdf5\n",
      "Epoch 46/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1160 - val_loss: 0.0795\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07317\n",
      "Epoch 47/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1119 - val_loss: 0.0705\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.07317 to 0.07054, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_047_Val_0.071.hdf5\n",
      "Epoch 48/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1122 - val_loss: 0.0830\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07054\n",
      "Epoch 49/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1097 - val_loss: 0.0752\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07054\n",
      "Epoch 50/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1078 - val_loss: 0.0901\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07054\n",
      "Epoch 51/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1086 - val_loss: 0.0802\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.07054\n",
      "Epoch 52/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1080 - val_loss: 0.0686\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.07054 to 0.06857, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_052_Val_0.069.hdf5\n",
      "Epoch 53/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1059 - val_loss: 0.1032\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.06857\n",
      "Epoch 54/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1074 - val_loss: 0.0689\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.06857\n",
      "Epoch 55/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1049 - val_loss: 0.0732\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.06857\n",
      "Epoch 56/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1042 - val_loss: 0.0792\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.06857\n",
      "Epoch 57/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1057 - val_loss: 0.0849\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.06857\n",
      "Epoch 58/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1038 - val_loss: 0.0743\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.06857\n",
      "Epoch 59/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1022 - val_loss: 0.0725\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.06857\n",
      "Epoch 60/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1017 - val_loss: 0.0679\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.06857 to 0.06790, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_060_Val_0.068.hdf5\n",
      "Epoch 61/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1027 - val_loss: 0.0695\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06790\n",
      "Epoch 62/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1011 - val_loss: 0.0727\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06790\n",
      "Epoch 63/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1003 - val_loss: 0.0758\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06790\n",
      "Epoch 64/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.1013 - val_loss: 0.0819\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06790\n",
      "Epoch 65/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1004 - val_loss: 0.0836\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.06790\n",
      "Epoch 66/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0982 - val_loss: 0.0700\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.06790\n",
      "Epoch 67/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0979 - val_loss: 0.0787\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06790\n",
      "Epoch 68/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0991 - val_loss: 0.0660\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06790 to 0.06601, saving model to ./Models/DNN_temp/valid_year_2017/Epoch_068_Val_0.066.hdf5\n",
      "Epoch 69/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0976 - val_loss: 0.0798\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06601\n",
      "Epoch 70/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0998 - val_loss: 0.0817\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06601\n",
      "Epoch 71/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0988 - val_loss: 0.0813\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06601\n",
      "Epoch 72/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1000 - val_loss: 0.0661\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06601\n",
      "Epoch 73/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0986 - val_loss: 0.0664\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06601\n",
      "Epoch 74/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0986 - val_loss: 0.0691\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06601\n",
      "Epoch 75/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0988 - val_loss: 0.0699\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06601\n",
      "Epoch 76/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0990 - val_loss: 0.0662\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06601\n",
      "Epoch 77/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0959 - val_loss: 0.0734\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06601\n",
      "Epoch 78/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0970 - val_loss: 0.0682\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06601\n",
      "Epoch 79/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0976 - val_loss: 0.0791\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06601\n",
      "Epoch 80/80\n",
      "592/592 [==============================] - 6s 11ms/step - loss: 0.0958 - val_loss: 0.0955\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06601\n",
      "Epoch 1/80\n",
      "  6/592 [..............................] - ETA: 6s - loss: 0.9998  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:52:09.372444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/592 [============================>.] - ETA: 0s - loss: 0.9673"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 14:52:15.842017: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.9672 - val_loss: 0.9179\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.91793, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_001_Val_0.918.hdf5\n",
      "Epoch 2/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.8617 - val_loss: 0.8150\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.91793 to 0.81503, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_002_Val_0.815.hdf5\n",
      "Epoch 3/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7880 - val_loss: 0.7630\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.81503 to 0.76299, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_003_Val_0.763.hdf5\n",
      "Epoch 4/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7377 - val_loss: 0.7260\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.76299 to 0.72598, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_004_Val_0.726.hdf5\n",
      "Epoch 5/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.7003 - val_loss: 0.7046\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.72598 to 0.70463, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_005_Val_0.705.hdf5\n",
      "Epoch 6/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.6588 - val_loss: 0.6459\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.70463 to 0.64587, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_006_Val_0.646.hdf5\n",
      "Epoch 7/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.6131 - val_loss: 0.5910\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.64587 to 0.59097, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_007_Val_0.591.hdf5\n",
      "Epoch 8/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.5707 - val_loss: 0.5609\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59097 to 0.56089, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_008_Val_0.561.hdf5\n",
      "Epoch 9/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.5307 - val_loss: 0.5257\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.56089 to 0.52569, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_009_Val_0.526.hdf5\n",
      "Epoch 10/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4954 - val_loss: 0.5010\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52569 to 0.50102, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_010_Val_0.501.hdf5\n",
      "Epoch 11/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4644 - val_loss: 0.4611\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.50102 to 0.46115, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_011_Val_0.461.hdf5\n",
      "Epoch 12/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.4311 - val_loss: 0.4354\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.46115 to 0.43537, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_012_Val_0.435.hdf5\n",
      "Epoch 13/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.4055 - val_loss: 0.4016\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43537 to 0.40158, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_013_Val_0.402.hdf5\n",
      "Epoch 14/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3845 - val_loss: 0.3911\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40158 to 0.39112, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_014_Val_0.391.hdf5\n",
      "Epoch 15/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3547 - val_loss: 0.3668\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.39112 to 0.36679, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_015_Val_0.367.hdf5\n",
      "Epoch 16/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3326 - val_loss: 0.3430\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.36679 to 0.34304, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_016_Val_0.343.hdf5\n",
      "Epoch 17/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.3089 - val_loss: 0.3163\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.34304 to 0.31630, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_017_Val_0.316.hdf5\n",
      "Epoch 18/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2880 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.31630 to 0.29823, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_018_Val_0.298.hdf5\n",
      "Epoch 19/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2685 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.29823 to 0.28153, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_019_Val_0.282.hdf5\n",
      "Epoch 20/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2527 - val_loss: 0.2597\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.28153 to 0.25973, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_020_Val_0.260.hdf5\n",
      "Epoch 21/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.2369 - val_loss: 0.2485\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25973 to 0.24850, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_021_Val_0.249.hdf5\n",
      "Epoch 22/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2237 - val_loss: 0.2392\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.24850 to 0.23915, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_022_Val_0.239.hdf5\n",
      "Epoch 23/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.2119 - val_loss: 0.2131\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23915 to 0.21312, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_023_Val_0.213.hdf5\n",
      "Epoch 24/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1990 - val_loss: 0.2122\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.21312 to 0.21218, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_024_Val_0.212.hdf5\n",
      "Epoch 25/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1869 - val_loss: 0.1983\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.21218 to 0.19831, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_025_Val_0.198.hdf5\n",
      "Epoch 26/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1776 - val_loss: 0.1912\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19831 to 0.19123, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_026_Val_0.191.hdf5\n",
      "Epoch 27/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1663 - val_loss: 0.1912\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19123 to 0.19119, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_027_Val_0.191.hdf5\n",
      "Epoch 28/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1559 - val_loss: 0.1626\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19119 to 0.16265, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_028_Val_0.163.hdf5\n",
      "Epoch 29/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1504 - val_loss: 0.1647\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16265\n",
      "Epoch 30/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1393 - val_loss: 0.1415\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.16265 to 0.14147, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_030_Val_0.141.hdf5\n",
      "Epoch 31/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1357 - val_loss: 0.1291\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.14147 to 0.12914, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_031_Val_0.129.hdf5\n",
      "Epoch 32/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1323 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.12914\n",
      "Epoch 33/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1265 - val_loss: 0.1258\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12914 to 0.12577, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_033_Val_0.126.hdf5\n",
      "Epoch 34/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1221 - val_loss: 0.1515\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.12577\n",
      "Epoch 35/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1195 - val_loss: 0.1492\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.12577\n",
      "Epoch 36/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1138 - val_loss: 0.1193\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.12577 to 0.11926, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_036_Val_0.119.hdf5\n",
      "Epoch 37/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1123 - val_loss: 0.1102\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11926 to 0.11025, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_037_Val_0.110.hdf5\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1106 - val_loss: 0.1256\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11025\n",
      "Epoch 39/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1081 - val_loss: 0.1220\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11025\n",
      "Epoch 40/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1074 - val_loss: 0.1301\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11025\n",
      "Epoch 41/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1071 - val_loss: 0.1176\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11025\n",
      "Epoch 42/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1053 - val_loss: 0.1244\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11025\n",
      "Epoch 43/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.1028 - val_loss: 0.1049\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.11025 to 0.10494, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_043_Val_0.105.hdf5\n",
      "Epoch 44/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1002 - val_loss: 0.1003\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.10494 to 0.10033, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_044_Val_0.100.hdf5\n",
      "Epoch 45/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0998 - val_loss: 0.1287\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.10033\n",
      "Epoch 46/80\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.1011 - val_loss: 0.1270\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.10033\n",
      "Epoch 47/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0996 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.10033\n",
      "Epoch 48/80\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.0973 - val_loss: 0.1149\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10033\n",
      "Epoch 49/80\n",
      "592/592 [==============================] - 7s 13ms/step - loss: 0.0979 - val_loss: 0.1141\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10033\n",
      "Epoch 50/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.1011 - val_loss: 0.1094\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10033\n",
      "Epoch 51/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0997 - val_loss: 0.1199\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10033\n",
      "Epoch 52/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0938 - val_loss: 0.1133\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10033\n",
      "Epoch 53/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0952 - val_loss: 0.1094\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10033\n",
      "Epoch 54/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0938 - val_loss: 0.1074\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10033\n",
      "Epoch 55/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0938 - val_loss: 0.1061\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10033\n",
      "Epoch 56/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0954 - val_loss: 0.1181\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10033\n",
      "Epoch 57/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0919 - val_loss: 0.1043\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10033\n",
      "Epoch 58/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0934 - val_loss: 0.1095\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10033\n",
      "Epoch 59/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0927 - val_loss: 0.1084\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10033\n",
      "Epoch 60/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0935 - val_loss: 0.0987\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.10033 to 0.09865, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_060_Val_0.099.hdf5\n",
      "Epoch 61/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0915 - val_loss: 0.1137\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.09865\n",
      "Epoch 62/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0928 - val_loss: 0.0980\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.09865 to 0.09804, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_062_Val_0.098.hdf5\n",
      "Epoch 63/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0931 - val_loss: 0.0992\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.09804\n",
      "Epoch 64/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0927 - val_loss: 0.1013\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.09804\n",
      "Epoch 65/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0906 - val_loss: 0.1159\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.09804\n",
      "Epoch 66/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0915 - val_loss: 0.1100\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.09804\n",
      "Epoch 67/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0910 - val_loss: 0.0876\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.09804 to 0.08760, saving model to ./Models/DNN_temp/valid_year_2018/Epoch_067_Val_0.088.hdf5\n",
      "Epoch 68/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0922 - val_loss: 0.1063\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08760\n",
      "Epoch 69/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0890 - val_loss: 0.1176\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08760\n",
      "Epoch 70/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0923 - val_loss: 0.0971\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08760\n",
      "Epoch 71/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0907 - val_loss: 0.1116\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08760\n",
      "Epoch 72/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0885 - val_loss: 0.1051\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08760\n",
      "Epoch 73/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0907 - val_loss: 0.1099\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08760\n",
      "Epoch 74/80\n",
      "592/592 [==============================] - 7s 11ms/step - loss: 0.0888 - val_loss: 0.1069\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08760\n",
      "Epoch 75/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0904 - val_loss: 0.1022\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08760\n",
      "Epoch 76/80\n",
      "592/592 [==============================] - 7s 13ms/step - loss: 0.0886 - val_loss: 0.0983\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.08760\n",
      "Epoch 77/80\n",
      "592/592 [==============================] - 8s 13ms/step - loss: 0.0910 - val_loss: 0.0965\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.08760\n",
      "Epoch 78/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0906 - val_loss: 0.1084\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.08760\n",
      "Epoch 79/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0891 - val_loss: 0.1042\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.08760\n",
      "Epoch 80/80\n",
      "592/592 [==============================] - 7s 12ms/step - loss: 0.0893 - val_loss: 0.1001\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.08760\n"
     ]
    }
   ],
   "source": [
    "\n",
    "year = 2013\n",
    "for train_x, train_y, valid_x, valid_y in zip(train_x_lst, train_y_lst, val_x_lst, val_y_lst):\n",
    "\n",
    "    model = make_model()\n",
    "    model.compile(optimizer='adam', loss = n_mae)\n",
    "    #model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "    #model.summary()\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode = 'min' , patience = 20, verbose = 1)\n",
    "    folder_path = './Models/DNN_temp/valid_year_{}'.format(year)\n",
    "    file_path = folder_path + '/Epoch_{epoch:03d}_Val_{val_loss:.3f}.hdf5'\n",
    "    mc = ModelCheckpoint(file_path, monitor='val_loss', mode='min',verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "    history = model.fit(train_x, train_y, epochs = 80, batch_size = 128, \\\n",
    "                        shuffle= True, validation_data = (valid_x, valid_y), \\\n",
    "                        verbose = 1, callbacks = [mc, es])\n",
    "    \n",
    "    year += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'train loss')\n",
    "plt.plot(history.history['val_loss'], label = 'validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2013 = make_model()\n",
    "model_2013.load_weights('./Models/DNN_temp/valid_year_2013/Epoch_048_Val_0.090.hdf5')\n",
    "\n",
    "model_2014 = make_model()\n",
    "model_2014.load_weights('./Models/DNN_temp/valid_year_2014/Epoch_043_Val_0.086.hdf5')\n",
    "\n",
    "model_2015 = make_model()\n",
    "model_2015.load_weights('./Models/DNN_temp/valid_year_2015/Epoch_047_Val_0.073.hdf5')\n",
    "\n",
    "model_2016 = make_model()\n",
    "model_2016.load_weights('./Models/DNN_temp/valid_year_2016/Epoch_046_Val_0.088.hdf5')\n",
    "\n",
    "model_2017 = make_model()\n",
    "model_2017.load_weights('./Models/DNN_temp/valid_year_2017/Epoch_048_Val_0.078.hdf5')\n",
    "\n",
    "model_2018 = make_model()\n",
    "model_2018.load_weights('./Models/DNN_temp/valid_year_2018/Epoch_048_Val_0.106.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_2013, model_2014, model_2015, model_2016, model_2017, model_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.load_weights('./Models/DNN_temp/valid_year_2015/Epoch_058_Val_0.068.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train_x, label = train_y)\n",
    "dval = xgb.DMatrix(data=val_x, label = val_y)\n",
    "wlist = [(dtrain, 'train'), (dval,'eval')]\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'metric':'mae', \n",
    "    'seed':42\n",
    "}\n",
    " \n",
    "\n",
    "model = xgb.train( params, dtrain, 500, evals=wlist, verbose_eval=20, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./Submission/test.csv')\n",
    "submission = pd.read_csv('./Submission/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자|시간|구분</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04 A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05 A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자|시간|구분\n",
       "0  2019-01-01 01 A\n",
       "1  2019-01-01 02 A\n",
       "2  2019-01-01 03 A\n",
       "3  2019-01-01 04 A\n",
       "4  2019-01-01 05 A"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자|시간|구분</th>\n",
       "      <th>공급량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05 A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자|시간|구분  공급량\n",
       "0  2019-01-01 01 A    0\n",
       "1  2019-01-01 02 A    0\n",
       "2  2019-01-01 03 A    0\n",
       "3  2019-01-01 04 A    0\n",
       "4  2019-01-01 05 A    0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime'] = test['일자|시간|구분'].str.split(' ').str[0]\n",
    "test['hour'] = test['일자|시간|구분'].str.split(' ').str[1].astype(int)\n",
    "test['company'] = test['일자|시간|구분'].str.split(' ').str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "test['year'] = test['datetime'].dt.year\n",
    "test['month'] = test['datetime'].dt.month\n",
    "test['day'] = test['datetime'].dt.day\n",
    "test['weekday'] = test['datetime'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['company'] = test['company'].map(company_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자|시간|구분</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>company</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 01 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 02 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 03 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 04 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 05 A</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자|시간|구분   datetime  hour  company  year  month  day  weekday\n",
       "0  2019-01-01 01 A 2019-01-01     1        0  2019      1    1        1\n",
       "1  2019-01-01 02 A 2019-01-01     2        0  2019      1    1        1\n",
       "2  2019-01-01 03 A 2019-01-01     3        0  2019      1    1        1\n",
       "3  2019-01-01 04 A 2019-01-01     4        0  2019      1    1        1\n",
       "4  2019-01-01 05 A 2019-01-01     5        0  2019      1    1        1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          일자|시간|구분   datetime  hour  company  year  month  day  weekday  \\\n",
      "0  2019-01-01 01 A 2019-01-01     1        0  2019      1    1        1   \n",
      "1  2019-01-01 02 A 2019-01-01     2        0  2019      1    1        1   \n",
      "2  2019-01-01 03 A 2019-01-01     3        0  2019      1    1        1   \n",
      "3  2019-01-01 04 A 2019-01-01     4        0  2019      1    1        1   \n",
      "4  2019-01-01 05 A 2019-01-01     5        0  2019      1    1        1   \n",
      "\n",
      "   temperature  \n",
      "0    -2.683333  \n",
      "1    -3.116667  \n",
      "2    -3.483333  \n",
      "3    -3.716667  \n",
      "4    -4.050000  \n",
      "              일자|시간|구분   datetime  hour  company  year  month  day  weekday  \\\n",
      "15115  2019-03-31 20 H 2019-03-31    20        6  2019      3   31        6   \n",
      "15116  2019-03-31 21 H 2019-03-31    21        6  2019      3   31        6   \n",
      "15117  2019-03-31 22 H 2019-03-31    22        6  2019      3   31        6   \n",
      "15118  2019-03-31 23 H 2019-03-31    23        6  2019      3   31        6   \n",
      "15119  2019-03-31 24 H 2019-03-31    24        6  2019      3   31        6   \n",
      "\n",
      "       temperature  \n",
      "15115    12.883333  \n",
      "15116    11.800000  \n",
      "15117    11.083333  \n",
      "15118    10.450000  \n",
      "15119     9.950000  \n"
     ]
    }
   ],
   "source": [
    "test_combined = pd.merge(test, daily_temp, how = 'left', left_on = ['month', 'day', 'hour'], right_on = ['month', 'day', 'hour'])\n",
    "\n",
    "print(test_combined.iloc[:5])\n",
    "print(test_combined.iloc[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68333333,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ],\n",
       "       [-3.11666667,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         2.        ],\n",
       "       [-3.48333333,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         3.        ],\n",
       "       [-3.71666667,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         4.        ],\n",
       "       [-4.05      ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         5.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = test_combined[features]\n",
    "\n",
    "test_x = test_x.values\n",
    "\n",
    "#test_x = x_scaler.transform(test_x)\n",
    "test_x[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:47.493773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1883.8281]\n",
      " [1664.449 ]\n",
      " [1596.1917]\n",
      " [1690.7303]\n",
      " [1831.1443]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:48.187852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1800.4664]\n",
      " [1651.8857]\n",
      " [1565.0012]\n",
      " [1657.2333]\n",
      " [1787.57  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:48.882474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1895.863 ]\n",
      " [1607.7179]\n",
      " [1525.3042]\n",
      " [1595.7412]\n",
      " [1681.7589]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:49.565560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1781.9425]\n",
      " [1615.4392]\n",
      " [1547.5463]\n",
      " [1652.0424]\n",
      " [1852.2092]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:50.262651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1898.8175]\n",
      " [1695.0132]\n",
      " [1619.2999]\n",
      " [1727.7306]\n",
      " [1922.3292]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 13:51:50.980368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1916.5156]\n",
      " [1631.5621]\n",
      " [1569.4972]\n",
      " [1688.542 ]\n",
      " [1815.7892]]\n"
     ]
    }
   ],
   "source": [
    "pred_lst = []\n",
    "for model in models:\n",
    "    pred = model.predict(test_x)\n",
    "    print(pred[:5])\n",
    "    pred_lst.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1862.9054, 1644.3447, 1570.4735, 1668.67  , 1815.1334],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.concatenate(pred_lst, axis = 1)\n",
    "preds[:5]\n",
    "\n",
    "preds_combined = np.mean(preds, axis = 1)\n",
    "preds_combined[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1916.5156]\n",
      " [1631.5621]\n",
      " [1569.4972]\n",
      " [1688.542 ]\n",
      " [1815.7892]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_x)\n",
    "print(pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['공급량'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./Submission/dnn_temp_2017.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
